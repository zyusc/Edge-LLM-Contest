{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8498f9f4-3d9a-481e-80fb-af41f7d7aa7d",
   "metadata": {},
   "source": [
    "# Pretraining Data Curation in NeMo Curator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d17c49",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Getting Started](#get-start)\n",
    "3. [RedPajama-Data-v2](#rpv2)\n",
    "4. [Data Preprocessing](#preprocess)\n",
    "5. [Deduplication](#dedup)\n",
    "6. [Quality filtering](#filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55d981",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "<a id=\"introduction\"></a>\n",
    "\n",
    "In this tutorial, we will show how to curate large-scale data for LLM pretraining in a distributed environment using NeMo-Curator. Specifically, we will focus on the following modules in NeMo-Curator:\n",
    "\n",
    "- Language identification and separation\n",
    "- Text reformatting and cleaning\n",
    "- Quality filtering\n",
    "- Document-level deduplication\n",
    "\n",
    "For demonstration, we will use the [RedPajama-Data-v2](#rpv2) dataset, an open dataset for LLM pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520eef06-0edb-4108-a048-af006dea8601",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1 System Information\n",
    "Here is the information on the system this notebook was run on:\n",
    "\n",
    "- **GPU**: 2 A100 nodes (each with 8 A100-SXM4-80GB)\n",
    "\n",
    "- **CUDA & Nvidia Drivers**: CUDA 12.4 with Driver 535.104.12\n",
    "\n",
    "- **OS**: Ubuntu 22.04.4 LTS\n",
    "\n",
    "## 1.2 Running NeMo-Curator\n",
    "\n",
    "NeMo-curator came pre-installed in Nemo Framework container. This notebook use 24.07 release of the NeMo Framework container. User can pull the container following the steps below:\n",
    "\n",
    "- Get access to the NeMo Framework container on [NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo)\n",
    "\n",
    "- Set your docker credentials\n",
    "\n",
    "\n",
    "    `docker login nvcr.io`\n",
    "\n",
    "    Username: `$oauthtoken`\n",
    "    \n",
    "    Password: `<NGC_API_KEY Key>`\n",
    "    \n",
    "- Pull the NeMo Framework Container image\n",
    "    \n",
    "    `docker pull docker pull nvcr.io/nvidia/nemo:24.07`\n",
    "\n",
    "Alternatively, NeMo-Curator is also available on [PyPi](https://pypi.org/project/nemo-curator/) and [GitHub](https://github.com/NVIDIA/NeMo-Curator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57dd35-cce6-4bfa-b34a-fb4a2ea584e0",
   "metadata": {},
   "source": [
    "# 2. Getting started\n",
    "<a id=\"get-start\"></a>\n",
    "\n",
    "NeMo-Curator uses dask for parallelization. Before we start using curator, we need to start a dask cluster. To start a multi-node dask cluster in slurm, we can use the `start-distributed-notebook.sh` script in this directory to start the cluster. The user will need to change the following variables:\n",
    "\n",
    "- Slurm job directives\n",
    "- Device type (`cpu` or `gpu`). Curator has both cpu and gpu modules. Check [here](https://docs.nvidia.com/nemo-framework/user-guide/latest/datacuration/cpuvsgpu.html) to see which modules are cpu/gpu\n",
    "- CPU related parameters if using cpu modules. Configure the number of workers and memory limit to efficiently use available computational resources while preventing out of memory\n",
    "- Path to the NeMo Framework container image\n",
    "- Path to `container-entrypoint.sh` script which is responsible for launching the dask schduler and workers\n",
    "\n",
    "Running the script will also launch a jupyter lab session on the rank 0 node and pass the dask schduler address as an environment variable that will be used later to connect to the dask client.\n",
    "\n",
    "The preprocessing modules such as Add ID and Text cleaning are cpu-based so we will start a cpu dask cluster first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de0fe93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dask.distributed import Client\n",
    "import warnings\n",
    "import dask.dataframe as dd\n",
    "import dask_cudf\n",
    "import cudf\n",
    "import gzip\n",
    "import json\n",
    "import dask.bag as db\n",
    "import glob\n",
    "from dask.distributed import wait\n",
    "import numpy as np\n",
    "\n",
    "from nemo_curator import get_client\n",
    "from nemo_curator.datasets import DocumentDataset\n",
    "from nemo_curator.utils.distributed_utils import (\n",
    "    get_num_workers,\n",
    "    read_data,\n",
    "    write_to_disk,\n",
    ")\n",
    "from nemo_curator.utils.file_utils import (\n",
    "    expand_outdir_and_mkdir, \n",
    "    get_all_files_paths_under, \n",
    "    separate_by_metadata,\n",
    "    get_batched_files,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "base_dir = \"/home/neelesh/4_new_c4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d728cab-d3ad-41b8-aae8-6e6927f7edaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1730894319.421165] [riogrande:2078536:0]          parser.c:2305 UCX  WARN  unused environment variable: UCX_MEMTYPE_CACHE (maybe: UCX_MEMTYPE_CACHE?)\n",
      "[1730894319.421165] [riogrande:2078536:0]          parser.c:2305 UCX  WARN  (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)\n",
      "cuDF Spilling is enabled\n",
      "Num Workers = 4\n"
     ]
    }
   ],
   "source": [
    "scheduler_address = os.getenv('SCHEDULER_ADDRESS')\n",
    "# cpu_client = get_client(\n",
    "#     cluster_type=\"cpu\",\n",
    "#     n_workers=64,                  # Number of workers, adjust to suit load (64 workers = 2 cores each)\n",
    "#     threads_per_worker=2,          # Threads per worker for I/O-bound tasks or to maintain high CPU utilization\n",
    "#     enable_spilling=True,          # Allow Dask to spill to disk when memory is tight\n",
    "#     protocol=\"tcp\",                # Communication protocol\n",
    "#     set_torch_to_use_rmm=False,    # Not applicable for CPU, but good to be explicit\n",
    "#     memory_limit=\"16GB\",           # Memory per worker, allowing flexibility within 1TB\n",
    "# )\n",
    "gpu_client = get_client(\n",
    "    cluster_type=\"gpu\",\n",
    "    n_workers=4,              # One worker per GPU\n",
    "    threads_per_worker=1,     # One thread per worker\n",
    "    rmm_pool_size=\"48GB\",     # Memory pool size per GPU\n",
    "    protocol=\"ucx\"           # Communication protocol\n",
    ")\n",
    "print(f\"Num Workers = {get_num_workers(gpu_client)}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab130e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_client.cluster.close()\n",
    "gpu_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf008174-a7b6-4a62-b421-0e3d84e305f2",
   "metadata": {},
   "source": [
    "# 3. RedPajama-Data-v2\n",
    "<a id=\"rpv2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d6014-a906-42dc-851e-d106d4db8d66",
   "metadata": {},
   "source": [
    "RedPajama-V2 (rpv2) is an advanced open-source initiative designed to support the development of large language models (LLMs). This dataset, sourced from 84 CommonCrawl snapshots, spans five major languages—English, French, Spanish, German, and Italian—making it one of the largest and most comprehensive public datasets available for LLM training.\n",
    "\n",
    "The RedPajama-V2 dataset is available on [Huggingface](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2).\n",
    "\n",
    "For this tutorial, we will start with a single snapshot from rpv2 and then scale to multiple snapshots to demonstrate the pre-training data curation workflow.\n",
    "\n",
    "The raw rpv2 data is stored in compressed json. We will first decompress the json.gz file and write them into jsonl files. For this, we will use a helper function `convert_json_gz_to_jsonl` in `helper.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192aafb0-524d-4a5e-85a0-a272f938d3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressing data took 0.00010585784912109375 s\n"
     ]
    }
   ],
   "source": [
    "from helper import convert_json_gz_to_jsonl\n",
    "\n",
    "input_data_dir = os.path.join(base_dir,\"c4/en\")\n",
    "output_data_dir = os.path.join(base_dir,\"../clean_c4\")\n",
    "\n",
    "t0 = time.time()\n",
    "# convert_json_gz_to_jsonl(input_data_dir, output_data_dir)\n",
    "print(f\"Uncompressing data took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b19e7-c6df-4519-8f82-97798cf39457",
   "metadata": {},
   "source": [
    "To get started, we can read the jsonl files into a `DocumentDataset` which is the standard format for text dataset used in curator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad35dcf-cd4b-4157-9bb2-14e90a8123fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 256 files\n"
     ]
    }
   ],
   "source": [
    "from nemo_curator.datasets import DocumentDataset\n",
    "# don't read in validation data\n",
    "input_dataset = DocumentDataset.read_json(output_data_dir, add_filename=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1152395-0928-4598-b36d-3a21cc221bf0",
   "metadata": {},
   "source": [
    "`DocumentDataset` is essentially a wrapper around dask dataframe and we can get the dataframe by calling `input_dataset.df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00fef38-0ae3-494d-9027-766f5c80d883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4-train.00004-of-01024.jsonl</td>\n",
       "      <td>New pictures from Ironman Hawaii and XTerra Ma...</td>\n",
       "      <td>2019-04-20 02:21:16+00:00</td>\n",
       "      <td>http://michiweiss.at/stories-pid386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4-train.00004-of-01024.jsonl</td>\n",
       "      <td>2) Given the cavitation on tight turns and pos...</td>\n",
       "      <td>2019-04-19 10:14:41+00:00</td>\n",
       "      <td>http://www.rib.net/forum/f36/engine-height-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4-train.00004-of-01024.jsonl</td>\n",
       "      <td>In the recording and in the PDF I explain my p...</td>\n",
       "      <td>2019-04-23 06:56:40+00:00</td>\n",
       "      <td>https://qualitytime-esl.com/spip.php?article467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4-train.00004-of-01024.jsonl</td>\n",
       "      <td>I picked up the bass a few months ago, and I'v...</td>\n",
       "      <td>2019-04-24 08:24:16+00:00</td>\n",
       "      <td>https://music.stackexchange.com/questions/5275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4-train.00004-of-01024.jsonl</td>\n",
       "      <td>Get lyrics of Cc dust new ways song you love. ...</td>\n",
       "      <td>2019-04-24 04:50:06+00:00</td>\n",
       "      <td>https://www.lyrics.cat/lyrics+cc+dust+new+ways</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0  c4-train.00004-of-01024.jsonl   \n",
       "1  c4-train.00004-of-01024.jsonl   \n",
       "2  c4-train.00004-of-01024.jsonl   \n",
       "3  c4-train.00004-of-01024.jsonl   \n",
       "4  c4-train.00004-of-01024.jsonl   \n",
       "\n",
       "                                                text  \\\n",
       "0  New pictures from Ironman Hawaii and XTerra Ma...   \n",
       "1  2) Given the cavitation on tight turns and pos...   \n",
       "2  In the recording and in the PDF I explain my p...   \n",
       "3  I picked up the bass a few months ago, and I'v...   \n",
       "4  Get lyrics of Cc dust new ways song you love. ...   \n",
       "\n",
       "                  timestamp                                                url  \n",
       "0 2019-04-20 02:21:16+00:00                http://michiweiss.at/stories-pid386  \n",
       "1 2019-04-19 10:14:41+00:00  http://www.rib.net/forum/f36/engine-height-pro...  \n",
       "2 2019-04-23 06:56:40+00:00    https://qualitytime-esl.com/spip.php?article467  \n",
       "3 2019-04-24 08:24:16+00:00  https://music.stackexchange.com/questions/5275...  \n",
       "4 2019-04-24 04:50:06+00:00     https://www.lyrics.cat/lyrics+cc+dust+new+ways  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336dc14d-7bcb-4f87-8821-d1fb43cd2a75",
   "metadata": {},
   "source": [
    "There are a total of 1,088,468,779 documents in this single snapshot.\n",
    "\n",
    "There are about 91 million for me - 91217230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57248718-a5cf-4028-81b8-1f4fa738ef68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91217230"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_dataset.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f309b95-5cfa-494c-94ed-b6162777005a",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing\n",
    "<a id=\"preprocess\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea58d4a",
   "metadata": {},
   "source": [
    "## 4.1 Data resharding\n",
    "\n",
    "The input text files have varying sizes, which leads to imbalanced partitions that could result in out-of-memory issues. Ideally, we want to make balanced text files of similar sizes. Curator offers utility to reshard the text files to simiar sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11494cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sharding took:53.97713375091553\n"
     ]
    }
   ],
   "source": [
    "from nemo_curator.utils.file_utils import reshard_jsonl\n",
    "from nemo_curator.utils.file_utils import expand_outdir_and_mkdir\n",
    "\n",
    "output_resharded_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_resharded\"))\n",
    "\n",
    "t0 = time.time()\n",
    "reshard_jsonl(\n",
    "    output_data_dir,\n",
    "    output_resharded_dir,\n",
    "    output_file_size=\"100M\",\n",
    "    start_index=0,\n",
    "    file_prefix=\"c4-train\",\n",
    ")\n",
    "print(f\"Data sharding took:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b85d83-fd01-49cd-8618-006cf6806461",
   "metadata": {},
   "source": [
    "[Optional] Removing the raw dataset to save disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50513f5-f530-400b-a0db-654a6b30bf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {base_dir}/rpv2-2023-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065cb25-9515-4c01-89b8-76e4eff6976f",
   "metadata": {},
   "source": [
    "## 4.2 Add ID\n",
    "\n",
    "We will assign a unique ID for each document in the dataset so we can refrence them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94403677-2b71-4f84-8dca-77d7482230a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator import AddId\n",
    "from nemo_curator.datasets import DocumentDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19380a4c-c612-49c3-9b91-02879f53dc65",
   "metadata": {},
   "source": [
    "We will create an instance of Curator's `AddId` class and use it to add ID for all documents in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f35cac5-f084-40cf-a2fd-7d232ddd5ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 11:24:40,146 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.28 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:43,206 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.05 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:45,575 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.27 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:47,184 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.92 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:47,373 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:49,586 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.24 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:50,724 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.64 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:51,311 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.10 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:52,002 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48408 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:52,001 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:37354 remote=tcp://127.0.0.1:46611>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:24:52,002 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40528 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:52,086 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:38618 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:52,256 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60448 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:52,322 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.86 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:52,555 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40878 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:54,164 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.85 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:54,284 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40884 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:54,461 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 6.00 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:55,261 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46611\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60462 remote=tcp://127.0.0.1:46611>: Stream is closed\n",
      "2024-11-03 11:24:55,299 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.88 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:55,755 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.91 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:55,870 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.97 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:55,946 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.15 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:56,159 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:56,520 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.52 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:57,014 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:57,316 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.76 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:59,379 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.04 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:59,763 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:24:59,948 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.85 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:00,318 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.32 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:00,609 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:02,140 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.09 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:02,596 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:02,882 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:39049 -> tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:39049 remote=tcp://127.0.0.1:45766>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:02,886 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47814 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:02,883 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:44570 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:02,932 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34172 remote=tcp://127.0.0.1:44423>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:03,016 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:36223 -> tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36223 remote=tcp://127.0.0.1:60906>: Stream is closed\n",
      "2024-11-03 11:25:03,527 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.34 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:03,829 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.06 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:03,827 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47788 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:03,837 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.44 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:04,570 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.62 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:04,578 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.89 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:04,750 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.13 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:05,484 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:35779 -> tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:35779 remote=tcp://127.0.0.1:57766>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:05,725 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.83 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:05,755 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55088 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:05,877 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:05,882 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.41 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:05,883 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:06,005 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:40951 -> tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:40951 remote=tcp://127.0.0.1:60726>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:06,006 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47838 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:06,158 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:35679 -> tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:35679 remote=tcp://127.0.0.1:45782>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:06,368 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 6.12 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:06,392 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.83 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:06,856 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:07,117 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.84 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:07,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.00 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:07,173 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:07,213 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 5.90 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:08,220 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44423\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55012 remote=tcp://127.0.0.1:44423>: Stream is closed\n",
      "2024-11-03 11:25:09,710 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:10,731 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37859 -> tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37859 remote=tcp://127.0.0.1:35720>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:10,739 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49262 remote=tcp://127.0.0.1:37723>: Stream is closed\n",
      "2024-11-03 11:25:10,793 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58876 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:10,804 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49294 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:11,092 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49276 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:11,117 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 6.48 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:11,147 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48820 remote=tcp://127.0.0.1:42629>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:11,150 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50992 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:11,151 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:39600 remote=tcp://127.0.0.1:42629>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:11,191 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41167 -> tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41167 remote=tcp://127.0.0.1:43038>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:11,203 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.75 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:11,203 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52974 remote=tcp://127.0.0.1:37723>: Stream is closed\n",
      "2024-11-03 11:25:11,640 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52970 remote=tcp://127.0.0.1:37723>: Stream is closed\n",
      "2024-11-03 11:25:11,928 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38727 -> tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38727 remote=tcp://127.0.0.1:59676>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:12,245 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 6.81 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:12,317 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:42591 -> tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:42591 remote=tcp://127.0.0.1:36768>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:12,360 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:38220 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:12,549 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:42610 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:12,935 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49280 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:13,030 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48836 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:13,033 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:39598 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:13,106 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58852 remote=tcp://127.0.0.1:37723>: Stream is closed\n",
      "2024-11-03 11:25:13,215 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40766 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:13,309 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52728 remote=tcp://127.0.0.1:37723>: Stream is closed\n",
      "2024-11-03 11:25:13,458 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:13,694 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:39620 remote=tcp://127.0.0.1:42629>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,211 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53152 remote=tcp://127.0.0.1:38945>: Stream is closed\n",
      "2024-11-03 11:25:14,226 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:46761 -> tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:46761 remote=tcp://127.0.0.1:40494>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,222 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34806 remote=tcp://127.0.0.1:38945>: Stream is closed\n",
      "2024-11-03 11:25:14,323 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49288 remote=tcp://127.0.0.1:37723>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,370 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.29 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:14,388 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45537 -> tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45537 remote=tcp://127.0.0.1:44574>: Stream is closed\n",
      "2024-11-03 11:25:14,395 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45283 -> tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45283 remote=tcp://127.0.0.1:33016>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,417 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60008 remote=tcp://127.0.0.1:36939>: Stream is closed\n",
      "2024-11-03 11:25:14,466 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:53170 remote=tcp://127.0.0.1:38945>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,725 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37191 -> tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37191 remote=tcp://127.0.0.1:60024>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,779 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:42729 -> tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:42729 remote=tcp://127.0.0.1:59740>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:14,885 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55100 remote=tcp://127.0.0.1:36939>: Stream is closed\n",
      "2024-11-03 11:25:15,268 - distributed.worker.memory - WARNING - Worker is at 71% memory usage. Resuming worker. Process memory: 5.62 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:15,337 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.86 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:15,342 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:39604 remote=tcp://127.0.0.1:42629>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:15,496 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40756 remote=tcp://127.0.0.1:42629>: Stream is closed\n",
      "2024-11-03 11:25:15,657 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-p3sjqixa/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20131%29#4' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20131%29#4'\n",
      "2024-11-03 11:25:15,678 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-p3sjqixa/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20175%29#27' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20175%29#27'\n",
      "2024-11-03 11:25:15,701 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-p3sjqixa/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20359%29#23' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20359%29#23'\n",
      "2024-11-03 11:25:15,701 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-p3sjqixa/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'\n",
      "2024-11-03 11:25:15,701 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-p3sjqixa' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/tmp/dask-scratch-space/worker-p3sjqixa'\n",
      "2024-11-03 11:25:15,772 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45311 -> tcp://127.0.0.1:42629\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45311 remote=tcp://127.0.0.1:34706>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:15,780 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.76 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:16,712 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41401 -> tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41401 remote=tcp://127.0.0.1:51032>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:16,710 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53144 remote=tcp://127.0.0.1:38945>: Stream is closed\n",
      "2024-11-03 11:25:16,718 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.02 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:16,814 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:39133 -> tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:39133 remote=tcp://127.0.0.1:36406>: BrokenPipeError: [Errno 32] Broken pipe\n",
      "2024-11-03 11:25:16,930 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:33770 remote=tcp://127.0.0.1:36939>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:17,269 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60506 remote=tcp://127.0.0.1:36939>: Stream is closed\n",
      "2024-11-03 11:25:17,637 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:17,830 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:44276 remote=tcp://127.0.0.1:36939>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:18,048 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:35779 -> tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:35779 remote=tcp://127.0.0.1:36470>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:18,297 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36939\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60012 remote=tcp://127.0.0.1:36939>: Stream is closed\n",
      "2024-11-03 11:25:18,306 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.04 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:18,324 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37723\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:18,857 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:34349 -> tcp://127.0.0.1:38945\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:34349 remote=tcp://127.0.0.1:42532>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:18,905 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.78 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:19,037 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:19,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.19 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:20,252 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.84 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:20,604 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:20,887 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.83 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:21,449 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:40924 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:21,491 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:22,241 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59124 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:22,273 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:43387 -> tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:43387 remote=tcp://127.0.0.1:59732>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:22,837 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:44218 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:22,936 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:40569 -> tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:40569 remote=tcp://127.0.0.1:56488>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:23,039 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53704 remote=tcp://127.0.0.1:42453>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:23,082 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49312 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:23,136 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:36315 -> tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36315 remote=tcp://127.0.0.1:53364>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:23,574 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.22 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:23,577 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49296 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:24,025 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:33510 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:24,843 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.32 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:24,901 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38377 -> tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38377 remote=tcp://127.0.0.1:38454>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:24,944 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.80 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:25,310 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42453\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41746 remote=tcp://127.0.0.1:42453>: Stream is closed\n",
      "2024-11-03 11:25:25,549 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.74 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:26,328 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.82 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:26,410 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.26 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:26,604 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.43 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:26,992 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.96 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:27,001 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37859 -> tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37859 remote=tcp://127.0.0.1:55402>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:27,003 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34798 remote=tcp://127.0.0.1:40029>: Stream is closed\n",
      "2024-11-03 11:25:27,001 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:39446 remote=tcp://127.0.0.1:40029>: Stream is closed\n",
      "2024-11-03 11:25:27,011 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41854 remote=tcp://127.0.0.1:40029>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:27,226 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34802 remote=tcp://127.0.0.1:40029>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:27,271 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.29 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:27,511 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34818 remote=tcp://127.0.0.1:40029>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:27,698 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.60 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:27,906 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,046 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.27 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,233 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.74 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,258 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:28,277 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56010 remote=tcp://127.0.0.1:40189>: Stream is closed\n",
      "2024-11-03 11:25:28,292 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.44 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,215 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:54484 remote=tcp://127.0.0.1:40189>: Stream is closed\n",
      "2024-11-03 11:25:28,388 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.45 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,585 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38824 remote=tcp://127.0.0.1:40189>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:28,625 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:28,913 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:34103 -> tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:34103 remote=tcp://127.0.0.1:46624>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:28,967 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:29,076 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:44933 -> tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:44933 remote=tcp://127.0.0.1:58064>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:29,177 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56806 remote=tcp://127.0.0.1:40029>: Stream is closed\n",
      "2024-11-03 11:25:29,147 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37191 -> tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37191 remote=tcp://127.0.0.1:56680>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:29,552 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52094 remote=tcp://127.0.0.1:40189>: Stream is closed\n",
      "2024-11-03 11:25:29,571 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40189\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34126 remote=tcp://127.0.0.1:40189>: Stream is closed\n",
      "2024-11-03 11:25:29,590 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:39398 remote=tcp://127.0.0.1:40029>: Stream is closed\n",
      "2024-11-03 11:25:30,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.69 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:30,547 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.24 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:30,578 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:39414 remote=tcp://127.0.0.1:40029>: Stream is closed\n",
      "2024-11-03 11:25:30,826 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:47720 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:30,826 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:47704 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:30,826 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:47712 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:30,828 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53846 remote=tcp://127.0.0.1:40969>: Stream is closed\n",
      "2024-11-03 11:25:30,867 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38727 -> tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38727 remote=tcp://127.0.0.1:44192>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:30,882 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:47708 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:30,839 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41624 remote=tcp://127.0.0.1:40969>: Stream is closed\n",
      "2024-11-03 11:25:30,955 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45275 -> tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45275 remote=tcp://127.0.0.1:50190>: BrokenPipeError: [Errno 32] Broken pipe\n",
      "2024-11-03 11:25:31,107 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41620 remote=tcp://127.0.0.1:40969>: Stream is closed\n",
      "2024-11-03 11:25:31,170 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 6.19 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:31,275 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:42222 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:31,584 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45635 -> tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45635 remote=tcp://127.0.0.1:42702>: Stream is closed\n",
      "2024-11-03 11:25:32,679 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.59 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:32,682 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53852 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:32,945 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.89 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:33,349 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:33,400 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:53478 remote=tcp://127.0.0.1:40969>: Stream is closed\n",
      "2024-11-03 11:25:33,712 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40029\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41844 remote=tcp://127.0.0.1:40029>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:35,009 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:35,108 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40969\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:47688 remote=tcp://127.0.0.1:40969>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:35,926 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.19 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:36,145 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.74 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:36,344 - distributed.worker.memory - WARNING - Worker is at 89% memory usage. Pausing worker.  Process memory: 7.03 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:36,776 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:37,071 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.31 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:37,760 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60216 remote=tcp://127.0.0.1:37277>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:37,783 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38295 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38295 remote=tcp://127.0.0.1:60172>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:37,786 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60204 remote=tcp://127.0.0.1:37277>: Stream is closed\n",
      "2024-11-03 11:25:37,796 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:43735 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:43735 remote=tcp://127.0.0.1:48170>: Stream is closed\n",
      "2024-11-03 11:25:37,828 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45213 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45213 remote=tcp://127.0.0.1:43382>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:37,838 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58038 remote=tcp://127.0.0.1:37277>: Stream is closed\n",
      "2024-11-03 11:25:38,058 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 6.20 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,126 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.43 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,134 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,378 - distributed.worker.memory - WARNING - Worker is at 66% memory usage. Resuming worker. Process memory: 5.25 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,526 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,734 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.30 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:38,866 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1419, in _connect\n",
      "    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:39,472 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45930 remote=tcp://127.0.0.1:45537>: Stream is closed\n",
      "2024-11-03 11:25:39,500 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45926 remote=tcp://127.0.0.1:45537>: Stream is closed\n",
      "2024-11-03 11:25:39,753 - distributed.worker.memory - WARNING - Worker is at 66% memory usage. Resuming worker. Process memory: 5.25 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:39,754 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:36299 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36299 remote=tcp://127.0.0.1:54494>: BrokenPipeError: [Errno 32] Broken pipe\n",
      "2024-11-03 11:25:39,759 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 6.28 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:39,955 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.24 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:39,991 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:33743 -> tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:33743 remote=tcp://127.0.0.1:35070>: Stream is closed\n",
      "2024-11-03 11:25:40,318 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.84 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:40,625 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.85 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:40,821 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:46139 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:46139 remote=tcp://127.0.0.1:35722>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:41,128 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:32919\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50820 remote=tcp://127.0.0.1:32919>: Stream is closed\n",
      "2024-11-03 11:25:41,129 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:32919\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50790 remote=tcp://127.0.0.1:32919>: Stream is closed\n",
      "2024-11-03 11:25:41,265 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37647 -> tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37647 remote=tcp://127.0.0.1:42014>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:41,304 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56094 remote=tcp://127.0.0.1:45537>: Stream is closed\n",
      "2024-11-03 11:25:41,478 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:41,546 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1419, in _connect\n",
      "    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:41,669 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38695 -> tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38695 remote=tcp://127.0.0.1:58884>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:41,708 - distributed.worker.memory - WARNING - Worker is at 90% memory usage. Pausing worker.  Process memory: 7.15 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:41,805 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.73 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:41,865 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1419, in _connect\n",
      "    async def _connect(self, addr: str, timeout: float | None = None) -> Comm:\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:42,649 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45010 remote=tcp://127.0.0.1:39049>: Stream is closed\n",
      "2024-11-03 11:25:42,431 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37277\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41590 remote=tcp://127.0.0.1:37277>: Stream is closed\n",
      "2024-11-03 11:25:42,785 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41219\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:54280 remote=tcp://127.0.0.1:41219>: Stream is closed\n",
      "2024-11-03 11:25:42,789 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41219\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:36768 remote=tcp://127.0.0.1:41219>: Stream is closed\n",
      "2024-11-03 11:25:42,845 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:42591 -> tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:42591 remote=tcp://127.0.0.1:45580>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:42,913 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41219\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:38606 remote=tcp://127.0.0.1:41219>: Stream is closed\n",
      "2024-11-03 11:25:42,913 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37435 -> tcp://127.0.0.1:41219\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37435 remote=tcp://127.0.0.1:45598>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:42,927 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41945 -> tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41945 remote=tcp://127.0.0.1:37616>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:43,116 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.57 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:43,380 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41219\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:54942 remote=tcp://127.0.0.1:41219>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:43,382 - distributed.worker.memory - WARNING - Worker is at 84% memory usage. Pausing worker.  Process memory: 6.65 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:43,405 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:41219\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 559, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f9f95b95720>: ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 366, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:43,450 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45012 remote=tcp://127.0.0.1:39049>: Stream is closed\n",
      "2024-11-03 11:25:43,722 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 297, in write\n",
      "    raise StreamClosedError()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2888, in get_data_from_worker\n",
      "    await comm.write(\"OK\")\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 307, in write\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58506 remote=tcp://127.0.0.1:39049>: Stream is closed\n",
      "2024-11-03 11:25:43,943 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/getitem-bb35c8ad0e6c52bbe913ae85df34f9a0#23' (failed in <built-in function unlink>): [Errno 2] No such file or directory: 'getitem-bb35c8ad0e6c52bbe913ae85df34f9a0#23'\n",
      "2024-11-03 11:25:43,943 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20878%29#7' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20878%29#7'\n",
      "2024-11-03 11:25:43,944 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20512%29#22' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20512%29#22'\n",
      "2024-11-03 11:25:43,944 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20113%29#6' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%20113%29#6'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20194%29#14' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20194%29#14'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20225%29#15' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20225%29#15'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%2077%29#8' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%2077%29#8'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20346%29#11' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20346%29#11'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20696%29#9' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20696%29#9'\n",
      "2024-11-03 11:25:43,961 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201485%29#27' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201485%29#27'\n",
      "2024-11-03 11:25:43,982 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:44,018 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/cumsum-1d3f8d11-18c8-4378-af60-acf68f71a1ed#12' (failed in <built-in function unlink>): [Errno 2] No such file or directory: 'cumsum-1d3f8d11-18c8-4378-af60-acf68f71a1ed#12'\n",
      "2024-11-03 11:25:44,018 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201053%29#3' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201053%29#3'\n",
      "2024-11-03 11:25:44,019 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'\n",
      "2024-11-03 11:25:44,019 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-rsli9286' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/tmp/dask-scratch-space/worker-rsli9286'\n",
      "2024-11-03 11:25:44,089 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-y3n5lirx/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20996%29#10' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20996%29#10'\n",
      "2024-11-03 11:25:44,089 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-y3n5lirx/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201245%29#1' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201245%29#1'\n",
      "2024-11-03 11:25:44,125 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-y3n5lirx/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'\n",
      "2024-11-03 11:25:44,125 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-y3n5lirx' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/tmp/dask-scratch-space/worker-y3n5lirx'\n",
      "2024-11-03 11:25:44,822 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:32919\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50700 remote=tcp://127.0.0.1:32919>: Stream is closed\n",
      "2024-11-03 11:25:44,920 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:45537\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:48686 remote=tcp://127.0.0.1:45537>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:46,226 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48938 remote=tcp://127.0.0.1:37583>: Stream is closed\n",
      "2024-11-03 11:25:46,227 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37652 remote=tcp://127.0.0.1:37583>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:46,291 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48944 remote=tcp://127.0.0.1:37583>: Stream is closed\n",
      "2024-11-03 11:25:46,319 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:46377 -> tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:46377 remote=tcp://127.0.0.1:45026>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:46,328 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:35163 -> tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:35163 remote=tcp://127.0.0.1:35532>: Stream is closed\n",
      "2024-11-03 11:25:46,443 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39049\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:33142 remote=tcp://127.0.0.1:39049>: Stream is closed\n",
      "2024-11-03 11:25:47,171 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.50 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:47,238 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:37474 remote=tcp://127.0.0.1:37583>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:47,239 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 6.17 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:47,676 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.75 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:48,302 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:48,855 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:48,899 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56558 remote=tcp://127.0.0.1:43473>: Stream is closed\n",
      "2024-11-03 11:25:48,899 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58080 remote=tcp://127.0.0.1:43473>: Stream is closed\n",
      "2024-11-03 11:25:48,901 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36916 remote=tcp://127.0.0.1:43473>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:48,901 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36904 remote=tcp://127.0.0.1:43473>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:48,978 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:44379 -> tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:44379 remote=tcp://127.0.0.1:37224>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:49,020 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 6.13 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:49,344 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:49,754 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 6.19 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:49,793 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37583\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:48926 remote=tcp://127.0.0.1:37583>: Stream is closed\n",
      "2024-11-03 11:25:49,857 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:50,079 - distributed.worker.memory - WARNING - Worker is at 64% memory usage. Resuming worker. Process memory: 5.05 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:50,350 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-_uy_73oz/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20180%29#17' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20180%29#17'\n",
      "2024-11-03 11:25:50,350 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-_uy_73oz/storage/%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201570%29#35' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d%27%2C%201570%29#35'\n",
      "2024-11-03 11:25:50,362 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.80 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:50,682 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:50,925 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46495\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41622 remote=tcp://127.0.0.1:46495>: Stream is closed\n",
      "2024-11-03 11:25:51,071 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46495\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:55890 remote=tcp://127.0.0.1:46495>: Stream is closed\n",
      "2024-11-03 11:25:51,508 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51442 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:51,505 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51434 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:51,512 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34798 remote=tcp://127.0.0.1:37191>: Stream is closed\n",
      "2024-11-03 11:25:51,623 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45720 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:51,892 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51444 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:51,949 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-bu9vslsq/storage/%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20667%29#6' (failed in <built-in function unlink>): [Errno 2] No such file or directory: '%28%27single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc%27%2C%20667%29#6'\n",
      "2024-11-03 11:25:51,949 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-bu9vslsq/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'\n",
      "2024-11-03 11:25:51,949 - distributed.diskutils - ERROR - Failed to remove '/tmp/dask-scratch-space/worker-bu9vslsq' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/tmp/dask-scratch-space/worker-bu9vslsq'\n",
      "2024-11-03 11:25:51,515 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51464 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:52,414 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56674 remote=tcp://127.0.0.1:37191>: Stream is closed\n",
      "2024-11-03 11:25:52,419 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46495\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49220 remote=tcp://127.0.0.1:46495>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:52,575 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46495\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45574 remote=tcp://127.0.0.1:46495>: Stream is closed\n",
      "2024-11-03 11:25:52,499 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:46495\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:33466 remote=tcp://127.0.0.1:46495>: Stream is closed\n",
      "2024-11-03 11:25:52,818 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58340 remote=tcp://127.0.0.1:43473>: Stream is closed\n",
      "2024-11-03 11:25:52,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.98 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:53,076 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.16 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:53,585 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51454 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:53,686 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:53,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.04 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:54,351 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:34689\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34334 remote=tcp://127.0.0.1:34689>: Stream is closed\n",
      "2024-11-03 11:25:54,485 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:54,700 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34796 remote=tcp://127.0.0.1:37191>: Stream is closed\n",
      "2024-11-03 11:25:54,844 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:44933 -> tcp://127.0.0.1:40951\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:44933 remote=tcp://127.0.0.1:53874>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:54,963 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:36093 -> tcp://127.0.0.1:34689\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:36093 remote=tcp://127.0.0.1:37198>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:55,264 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:51472 remote=tcp://127.0.0.1:37191>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:55,562 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37191\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56656 remote=tcp://127.0.0.1:37191>: Stream is closed\n",
      "2024-11-03 11:25:55,679 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:56828 remote=tcp://127.0.0.1:35679>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:55,758 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 6.50 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:56,235 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:25:56,402 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.32 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:56,420 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.30 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:56,206 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:33378 remote=tcp://127.0.0.1:35679>: Stream is closed\n",
      "2024-11-03 11:25:56,929 - distributed.worker.memory - WARNING - Worker is at 66% memory usage. Resuming worker. Process memory: 5.27 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:57,044 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43473\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:58352 remote=tcp://127.0.0.1:43473>: Stream is closed\n",
      "2024-11-03 11:25:57,143 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:45670 remote=tcp://127.0.0.1:35679>: Stream is closed\n",
      "2024-11-03 11:25:57,585 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 6.48 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:57,736 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38295 -> tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38295 remote=tcp://127.0.0.1:48888>: Stream is closed\n",
      "2024-11-03 11:25:57,954 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.32 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:57,972 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.15 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:57,995 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.30 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:58,292 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:56812 remote=tcp://127.0.0.1:35679>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:58,299 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:40951\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59738 remote=tcp://127.0.0.1:40951>: Stream is closed\n",
      "2024-11-03 11:25:58,569 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41945 -> tcp://127.0.0.1:35679\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41945 remote=tcp://127.0.0.1:49738>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:25:58,789 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.45 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:59,143 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 6.14 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:25:59,228 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:00,295 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.32 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:00,649 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.31 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:00,820 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:01,509 - distributed.worker.memory - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 5.68 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:02,155 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.58 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:02,240 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.98 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:02,992 - distributed.worker.memory - WARNING - Worker is at 65% memory usage. Resuming worker. Process memory: 5.18 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:03,424 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:03,443 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 6.28 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:04,095 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:04,781 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.39 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:05,399 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.14 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:05,865 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.39 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:07,039 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42591\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60938 remote=tcp://127.0.0.1:42591>: Stream is closed\n",
      "2024-11-03 11:26:07,181 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:07,268 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:44446 remote=tcp://127.0.0.1:44379>: Stream is closed\n",
      "2024-11-03 11:26:07,268 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41054 remote=tcp://127.0.0.1:44379>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:07,310 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51372 remote=tcp://127.0.0.1:44379>: Stream is closed\n",
      "2024-11-03 11:26:07,849 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41165 -> tcp://127.0.0.1:42591\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41165 remote=tcp://127.0.0.1:59266>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:08,984 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:41070 remote=tcp://127.0.0.1:44379>: Stream is closed\n",
      "2024-11-03 11:26:09,680 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.78 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:10,177 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:45341 -> tcp://127.0.0.1:42591\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:45341 remote=tcp://127.0.0.1:51090>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:10,197 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.58 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:09,960 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41945 -> tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41945 remote=tcp://127.0.0.1:40856>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:11,490 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.73 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:11,669 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.01 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:11,735 - distributed.worker.memory - WARNING - Worker is at 71% memory usage. Resuming worker. Process memory: 5.60 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:12,211 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.45 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:12,641 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.27 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:13,075 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:13,468 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42591\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60944 remote=tcp://127.0.0.1:42591>: Stream is closed\n",
      "2024-11-03 11:26:13,550 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:42591\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 377, in connect\n",
      "    handshake = await comm.read()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:26:13,558 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:44379\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1425, in _connect\n",
      "    comm = await connect(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils.py\", line 1926, in wait_for\n",
      "    return await asyncio.wait_for(fut, timeout)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/asyncio/tasks.py\", line 432, in wait_for\n",
      "    await waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1535, in connect\n",
      "    return connect_attempt.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2871, in get_data_from_worker\n",
      "    comm = await rpc.connect(worker)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1537, in connect\n",
      "    raise CommClosedError(reason)\n",
      "distributed.comm.core.CommClosedError: Address removed.\n",
      "2024-11-03 11:26:13,763 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39133\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:54108 remote=tcp://127.0.0.1:39133>: Stream is closed\n",
      "2024-11-03 11:26:13,892 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:38695 -> tcp://127.0.0.1:39133\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:38695 remote=tcp://127.0.0.1:41336>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:14,064 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.47 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:15,242 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:37269 -> tcp://127.0.0.1:39133\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:37269 remote=tcp://127.0.0.1:52436>: Stream is closed\n",
      "2024-11-03 11:26:15,987 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.33 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:16,007 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39133\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:34990 remote=tcp://127.0.0.1:39133>: Stream is closed\n",
      "2024-11-03 11:26:16,462 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.81 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:17,157 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.14 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:18,628 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.09 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:19,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.81 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:19,522 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.43 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:20,720 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.41 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:21,140 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.28 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:21,915 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.86 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:21,977 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.39 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:22,031 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.03 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:22,048 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37269\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:43080 remote=tcp://127.0.0.1:37269>: Stream is closed\n",
      "2024-11-03 11:26:22,048 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37269\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59004 remote=tcp://127.0.0.1:37269>: Stream is closed\n",
      "2024-11-03 11:26:22,049 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37269\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:43068 remote=tcp://127.0.0.1:37269>: Stream is closed\n",
      "2024-11-03 11:26:22,050 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37269\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:60484 remote=tcp://127.0.0.1:37269>: Stream is closed\n",
      "2024-11-03 11:26:22,133 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.02 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:22,398 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.40 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:22,842 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 6.46 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:23,691 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.94 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:23,716 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:37269\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:52502 remote=tcp://127.0.0.1:37269>: Stream is closed\n",
      "2024-11-03 11:26:24,184 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:24,464 - distributed.worker.memory - WARNING - Worker is at 86% memory usage. Pausing worker.  Process memory: 6.78 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:24,780 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 6.49 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:25,145 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.39 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:25,382 - distributed.worker.memory - WARNING - Worker is at 69% memory usage. Resuming worker. Process memory: 5.48 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:25,390 - distributed.worker.memory - WARNING - Worker is at 64% memory usage. Resuming worker. Process memory: 5.05 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:25,854 - distributed.worker.memory - WARNING - Worker is at 73% memory usage. Resuming worker. Process memory: 5.77 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:26,512 - distributed.worker.memory - WARNING - Worker is at 67% memory usage. Resuming worker. Process memory: 5.31 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:26,899 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.34 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:28,198 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:28,367 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.30 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:28,433 - distributed.worker.memory - WARNING - Worker is at 66% memory usage. Resuming worker. Process memory: 5.24 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:28,819 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 6.43 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:29,447 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.25 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:29,456 - distributed.worker.memory - WARNING - Worker is at 72% memory usage. Resuming worker. Process memory: 5.72 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:30,091 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.42 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:30,523 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.36 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:30,666 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:30,805 - distributed.worker.memory - WARNING - Worker is at 66% memory usage. Resuming worker. Process memory: 5.23 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:30,903 - distributed.worker.memory - WARNING - Worker is at 75% memory usage. Resuming worker. Process memory: 5.93 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:31,244 - distributed.worker.memory - WARNING - Worker is at 83% memory usage. Pausing worker.  Process memory: 6.55 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:31,539 - distributed.worker.memory - WARNING - Worker is at 85% memory usage. Pausing worker.  Process memory: 6.73 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:31,912 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.38 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:32,438 - distributed.worker.memory - WARNING - Worker is at 70% memory usage. Resuming worker. Process memory: 5.56 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:32,754 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.37 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:33,022 - distributed.worker.memory - WARNING - Worker is at 70% memory usage. Resuming worker. Process memory: 5.59 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:34,335 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39229\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59274 remote=tcp://127.0.0.1:39229>: Stream is closed\n",
      "2024-11-03 11:26:34,350 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:41167 -> tcp://127.0.0.1:39229\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:41167 remote=tcp://127.0.0.1:37840>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:34,395 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:44933 -> tcp://127.0.0.1:39229\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 861, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/iostream.py\", line 1116, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1778, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:44933 remote=tcp://127.0.0.1:40966>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "2024-11-03 11:26:34,725 - distributed.worker.memory - WARNING - Worker is at 68% memory usage. Resuming worker. Process memory: 5.39 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:34,793 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:39229\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 227, in read\n",
      "    frames_nosplit = await read_bytes_rw(stream, frames_nosplit_nbytes)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2056, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 2874, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59286 remote=tcp://127.0.0.1:39229>: Stream is closed\n",
      "2024-11-03 11:26:35,564 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 6.35 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:37,215 - distributed.worker.memory - WARNING - Worker is at 74% memory usage. Resuming worker. Process memory: 5.87 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:40,135 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.07 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:26:40,153 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 4.97 GiB -- Worker memory limit: 7.87 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 11:24:51,995 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:46611 (pid=1817850) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:24:52,054 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:46611' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1551), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 978), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 78), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1666), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 678), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1364), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 607), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 4), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 658), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 796), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1016), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1450), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1591), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1359), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 747)} (stimulus_id='handle-worker-cleanup-1730633092.0541036')\n",
      "2024-11-03 11:24:54,115 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:02,878 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:44423 (pid=1818194) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:02,942 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:44423' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1310), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1689), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 483), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 761), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 466), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1215), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 641), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 792), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1548), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1178)} (stimulus_id='handle-worker-cleanup-1730633102.9424028')\n",
      "2024-11-03 11:25:04,524 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:10,697 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:37723 (pid=1817615) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:10,732 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:37723' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1535), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 219), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1373), 'getitem-05a27066e98675db6073b85a787c5d44', ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 387), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 854), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 288), 'getitem-ef4b8d5a84d0ff49f0f7c590d786225a', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 818), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 905), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1532), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1516)} (stimulus_id='handle-worker-cleanup-1730633110.732009')\n",
      "2024-11-03 11:25:11,142 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:42629 (pid=1817744) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:11,208 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:42629' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 220), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 283), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1380), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 120), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 245), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1505), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 312), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 585), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1662), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 578), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 889), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1324), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1288), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 644), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1728), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 166), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1117)} (stimulus_id='handle-worker-cleanup-1730633111.2083206')\n",
      "2024-11-03 11:25:14,003 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:14,195 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:38945 (pid=1817586) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:14,314 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:38945' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 943), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 476), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1653), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 103), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 161), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 70), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1192), 'getitem-2b8c42c45fcdba50b0abfbb6fa93b7c1', 'getitem-4f9e2f256491d5e303d4267fb62e52e5', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1579), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1621), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1319), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1697), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 398), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 272), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1056), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 83), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 510), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 766)} (stimulus_id='handle-worker-cleanup-1730633114.313711')\n",
      "2024-11-03 11:25:14,383 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:36939 (pid=1818021) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:14,584 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:36939' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 175), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 383), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1113), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1321), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 359), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 131), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 430), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 8), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 757), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 584), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1612), 'getitem-63a5b5f2829068b99d93a6502f84c256', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 959)} (stimulus_id='handle-worker-cleanup-1730633114.5844655')\n",
      "2024-11-03 11:25:14,860 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:17,085 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:17,162 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:21,294 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:42453 (pid=1817624) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:21,386 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:42453' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'getitem-7c3589e8ac4c43c053da30ef406ca964', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 207), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 447), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 975), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1772), 'getitem-e52a18ce3be6cfba78117afabc1e0d1c', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 941), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 214), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1121), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 831), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 927), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1172), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1111), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1477)} (stimulus_id='handle-worker-cleanup-1730633121.385955')\n",
      "2024-11-03 11:25:23,008 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:26,997 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:40029 (pid=1818115) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:27,112 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40029' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1422), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 759), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 114), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 525), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 367), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 20), 'getitem-bc8e9a8b34ff68f2688dc3afd583ae82', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 473), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1402), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 951), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1546), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 893), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1523), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 95), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 470), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1252)} (stimulus_id='handle-worker-cleanup-1730633127.1119404')\n",
      "2024-11-03 11:25:28,005 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:40189 (pid=1817479) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:28,075 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40189' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1011), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 673), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 348), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 862), 'getitem-42d12e8f8b89c3818ca321f01072d223', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 646), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1048), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 845), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1157), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1726), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 758), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 619), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1346), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1766), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1339), 'getitem-eded0c10acaa7126952ece7df7663a2d', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1336), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1201)} (stimulus_id='handle-worker-cleanup-1730633128.0751462')\n",
      "2024-11-03 11:25:29,131 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:30,422 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:30,820 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:40969 (pid=1817535) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:30,909 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40969' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 618), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 669), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1229), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 681), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1511), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 539), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1626), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 738), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1494), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 303), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1423), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 557), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 425), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1381)} (stimulus_id='handle-worker-cleanup-1730633130.9087553')\n",
      "2024-11-03 11:25:33,033 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:37,756 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:37277 (pid=1818105) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:37,904 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:37277' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 865), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 338), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 457), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1129), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 164), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 275), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 989), 'getitem-3184684b2898215199353c3d91289c94', 'getitem-db67af7bb012c32aa81fe2b787ccc92c', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 333), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 992), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 972), 'getitem-245a8c9ea965d93ee299446e07924af1', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1426)} (stimulus_id='handle-worker-cleanup-1730633137.9042242')\n",
      "2024-11-03 11:25:39,468 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:45537 (pid=1818146) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:39,548 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:45537' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 399), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1723), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1303), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 183), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 961), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1516), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 716), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1720), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 330), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 703), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 426), 'getitem-d8dea231df8d54ec41208717743523b0', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1629), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1073), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 966), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 102), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 108), 'getitem-18f705e3d65ae623dcc028db418d5bf2'} (stimulus_id='handle-worker-cleanup-1730633139.5477033')\n",
      "2024-11-03 11:25:39,637 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:41,121 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:32919 (pid=1817807) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:41,300 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:32919' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 281), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 39), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1036), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1375), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1449), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1438), 'getitem-304db5e5fa1f25bac56eab97f6abd22d', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1379), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 725), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1760), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1096), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1266), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 838), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1558), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 950), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 496), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 969)} (stimulus_id='handle-worker-cleanup-1730633141.300036')\n",
      "2024-11-03 11:25:41,731 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:42,645 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:39049 (pid=1817543) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:42,775 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:41219 (pid=1817737) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:42,854 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:39049' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 878), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1020), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 77), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 113), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 225), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 311), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1606), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1292), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 696), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1485), 'getitem-bb35c8ad0e6c52bbe913ae85df34f9a0', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 424), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 512), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 346), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1124), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 680), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1053), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 194)} (stimulus_id='handle-worker-cleanup-1730633142.8541954')\n",
      "2024-11-03 11:25:42,991 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:41219' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1371), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 184), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 798), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1245), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1094), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 884), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 889), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 83), 'getitem-8cb44de88fc45d8a7265fb6fa42f632b', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 996), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1138), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 221), 'getitem-2183a0b48df9b7b11c46736d5fe8be82', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 106), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1356), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 256), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 911)} (stimulus_id='handle-worker-cleanup-1730633142.991063')\n",
      "2024-11-03 11:25:43,201 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:44,690 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:44,778 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:46,221 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:37583 (pid=1818199) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:46,300 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:37583' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1620), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 730), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 238), 'getitem-dce18ec24526730324e920fe46434118', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1550), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1624), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 376), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 246), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 819), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 848), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 555), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 50), 'getitem-a3c876bce06762fb4fee21e4cee1a4cc', ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1762), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 615), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1072)} (stimulus_id='handle-worker-cleanup-1730633146.2999623')\n",
      "2024-11-03 11:25:48,895 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:43473 (pid=1818300) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:49,139 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:43473' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'getitem-ac1fdc42b2e13b4b3b50d407fc18e332', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1361), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1570), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 325), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 87), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1562), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 562), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 180), 'getitem-68d5d188fa9f848469064b07bb3feff4', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1067), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1366), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1202), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 568), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 442), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1553), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1207)} (stimulus_id='handle-worker-cleanup-1730633149.1394553')\n",
      "2024-11-03 11:25:49,542 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:50,810 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:46495 (pid=1817620) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:50,983 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:46495' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1456), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1759), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1329), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 302), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1417), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 890), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 694), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 150), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 240), 'getitem-5adcaaf6b1a49f3bb9649d9fea1e47af', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 529), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1767), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1534), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 667), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 445), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1156)} (stimulus_id='handle-worker-cleanup-1730633150.9832013')\n",
      "2024-11-03 11:25:51,172 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:51,485 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:37191 (pid=1817643) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:51,672 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:37191' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1411), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1155), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 974), 'getitem-084fb163aaa5e12662ab4dc49d1a672f', ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 398), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 19), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1443), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 138), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 803), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 777), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 43), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 712), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1712), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 255)} (stimulus_id='handle-worker-cleanup-1730633151.67185')\n",
      "2024-11-03 11:25:53,567 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:53,919 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:54,226 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:34689 (pid=1817567) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:54,337 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:34689' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1492), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 743), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 7), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1439), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 588), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1698), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 315), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1590), 'getitem-812cb53c5cf1efdc8dfd6e4943f876d8', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 612), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1047), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 85)} (stimulus_id='handle-worker-cleanup-1730633154.3372738')\n",
      "2024-11-03 11:25:54,820 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:40951 (pid=1817519) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:54,914 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40951' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1240), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 817), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1627), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 453), 'getitem-bc8e9a8b34ff68f2688dc3afd583ae82', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 964), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1430), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 349), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1015), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 439), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1634), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 821)} (stimulus_id='handle-worker-cleanup-1730633154.9144757')\n",
      "2024-11-03 11:25:55,519 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:35679 (pid=1817809) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:25:55,672 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:35679' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 281), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 264), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1264), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 572), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 922), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1617), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 851), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 41), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 269), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 112), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1070), 'getitem-9610f064c70d9cae7ba7d1b0ceb542b8', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1756), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 280)} (stimulus_id='handle-worker-cleanup-1730633155.6726377')\n",
      "2024-11-03 11:25:57,149 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:57,287 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:25:59,890 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:26:05,686 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:42591 (pid=1817488) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:26:05,713 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:42591' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1415), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 213), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 579), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 389), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1547), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 50), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 623), 'getitem-eac17f0810d8eb34ae73784d62b82695', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 928), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 664), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 889), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 31), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 336), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 676)} (stimulus_id='handle-worker-cleanup-1730633165.712822')\n",
      "2024-11-03 11:26:07,261 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:44379 (pid=1817929) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:26:07,328 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:26:07,397 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:44379' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 415), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1239), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 592), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 52), 'getitem-61c9d07c003721f6bfcb687c6fad8444', ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 916), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 421), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 353), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1419), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 818), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1399), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1393), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 937), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1738)} (stimulus_id='handle-worker-cleanup-1730633167.3968492')\n",
      "2024-11-03 11:26:09,389 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:26:13,757 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:39133 (pid=1817476) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:26:13,880 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:39133' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 65), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 493), ('delayed-container-af1864f2b2f6051d1a3418ded45422f0', 1318), 'getitem-e803cae339dd25f177ab6a950cc2bc19', ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 183), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 222), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 196), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1238), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 334), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1376), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 960), 'getitem-388a828b8186829bab13c6873e8c2d0e', ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 348), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 580), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 885)} (stimulus_id='handle-worker-cleanup-1730633173.8804579')\n",
      "2024-11-03 11:26:15,460 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:26:22,038 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:37269 (pid=1817540) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:26:22,061 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:37269' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1573), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 904), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 679), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 737), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 322), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1408), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 202), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 51), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1234), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 452), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1493), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 471), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1362), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1341)} (stimulus_id='handle-worker-cleanup-1730633182.0612185')\n",
      "2024-11-03 11:26:25,639 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-11-03 11:26:34,328 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:39229 (pid=1818039) exceeded 95% memory budget. Restarting...\n",
      "2024-11-03 11:26:34,356 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:39229' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 425), 'getitem-4b12a818ed32d9753138a53dac7fa9e8', ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 130), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1688), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1267), ('fromdelayed-f141b05d3b8fc27e1ec74a5294116bbf', 1160), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 527), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 790), ('read_single_partition-4a9a9f1ea059ff8f82367e0c758d515d', 1090), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 308), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 674), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 613), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 394), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1561), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 436), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1715), ('single_partition_write_with_filename-4863f13ca84970ad3e41f8c436f8d4fc', 1335)} (stimulus_id='handle-worker-cleanup-1730633194.3562322')\n",
      "2024-11-03 11:26:35,091 - distributed.nanny - WARNING - Restarting worker\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2861484' coro=<Client._gather.<locals>.wait() done, defined at /home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 1792 partitions\n",
      "Adding ID took :296.1998860836029\n"
     ]
    }
   ],
   "source": [
    "input_data_dir = os.path.join(base_dir,\"../clean_c4_resharded\")\n",
    "input_dataset = DocumentDataset.read_json(input_data_dir, add_filename=True)\n",
    "id_data_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_resharded_with_id\"))\n",
    "\n",
    "t0 = time.time()\n",
    "# specify add_id function\n",
    "add_id = AddId(\n",
    "    id_field=\"id\",\n",
    "    id_prefix=\"c4-train\",\n",
    "    start_index=0,\n",
    ")\n",
    "id_dataset = add_id(input_dataset)\n",
    "id_dataset.to_json(id_data_dir, write_to_filename=True)\n",
    "print(f\"Adding ID took :{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c79824-efc0-4895-a85f-03387c0c90ea",
   "metadata": {},
   "source": [
    "We can validate the added IDs below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "908d0a01-96b9-4ad4-9fb7-cf0148640bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 11:29:47,637 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.60 GiB -- Worker memory limit: 7.87 GiB\n",
      "2024-11-03 11:30:28,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 5.59 GiB -- Worker memory limit: 7.87 GiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4-train00000.jsonl</td>\n",
       "      <td>New pictures from Ironman Hawaii and XTerra Ma...</td>\n",
       "      <td>2019-04-20 02:21:16+00:00</td>\n",
       "      <td>http://michiweiss.at/stories-pid386</td>\n",
       "      <td>c4-train-0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4-train00000.jsonl</td>\n",
       "      <td>2) Given the cavitation on tight turns and pos...</td>\n",
       "      <td>2019-04-19 10:14:41+00:00</td>\n",
       "      <td>http://www.rib.net/forum/f36/engine-height-pro...</td>\n",
       "      <td>c4-train-0000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4-train00000.jsonl</td>\n",
       "      <td>In the recording and in the PDF I explain my p...</td>\n",
       "      <td>2019-04-23 06:56:40+00:00</td>\n",
       "      <td>https://qualitytime-esl.com/spip.php?article467</td>\n",
       "      <td>c4-train-0000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4-train00000.jsonl</td>\n",
       "      <td>I picked up the bass a few months ago, and I'v...</td>\n",
       "      <td>2019-04-24 08:24:16+00:00</td>\n",
       "      <td>https://music.stackexchange.com/questions/5275...</td>\n",
       "      <td>c4-train-0000000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4-train00000.jsonl</td>\n",
       "      <td>Get lyrics of Cc dust new ways song you love. ...</td>\n",
       "      <td>2019-04-24 04:50:06+00:00</td>\n",
       "      <td>https://www.lyrics.cat/lyrics+cc+dust+new+ways</td>\n",
       "      <td>c4-train-0000000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                               text  \\\n",
       "0  c4-train00000.jsonl  New pictures from Ironman Hawaii and XTerra Ma...   \n",
       "1  c4-train00000.jsonl  2) Given the cavitation on tight turns and pos...   \n",
       "2  c4-train00000.jsonl  In the recording and in the PDF I explain my p...   \n",
       "3  c4-train00000.jsonl  I picked up the bass a few months ago, and I'v...   \n",
       "4  c4-train00000.jsonl  Get lyrics of Cc dust new ways song you love. ...   \n",
       "\n",
       "                  timestamp  \\\n",
       "0 2019-04-20 02:21:16+00:00   \n",
       "1 2019-04-19 10:14:41+00:00   \n",
       "2 2019-04-23 06:56:40+00:00   \n",
       "3 2019-04-24 08:24:16+00:00   \n",
       "4 2019-04-24 04:50:06+00:00   \n",
       "\n",
       "                                                 url                   id  \n",
       "0                http://michiweiss.at/stories-pid386  c4-train-0000000000  \n",
       "1  http://www.rib.net/forum/f36/engine-height-pro...  c4-train-0000000001  \n",
       "2    https://qualitytime-esl.com/spip.php?article467  c4-train-0000000002  \n",
       "3  https://music.stackexchange.com/questions/5275...  c4-train-0000000003  \n",
       "4     https://www.lyrics.cat/lyrics+cc+dust+new+ways  c4-train-0000000004  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d3685-c6b8-4042-a8f2-bda664773327",
   "metadata": {},
   "source": [
    "[Optional] Remove the sharded dataset to save disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa333bc-2de9-4c56-b8ff-c76ed21298aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "filedescriptor out of range in select()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrm -rf \u001b[39;49m\u001b[38;5;132;43;01m{base_dir}\u001b[39;49;00m\u001b[38;5;124;43m/../clean_c4_resharded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    152\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m     flush()\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pexpect/spawnbase.py:383\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expect_async(exp, timeout)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pexpect/pty_spawn.py:458\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m select_ignore_interrupts([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_fd], [], [], timeout)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# If there is data available to read right now, read as much as\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# we can. We do this to increase performance if there are a lot\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# of bytes to be read. This also avoids calling isalive() too\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# often. See also:\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# * https://github.com/pexpect/pexpect/pull/304\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# * http://trac.sagemath.org/ticket/10295\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m         incoming \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m         err \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: filedescriptor out of range in select()"
     ]
    }
   ],
   "source": [
    "!rm -rf {base_dir}/../clean_c4_resharded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18752f5-b505-415c-960b-be7b396b9b78",
   "metadata": {},
   "source": [
    "## 4.3 Language ID and Separation\n",
    "\n",
    "Data curation usually includes steps that are language specific (e.g. using language-tuned heuristics for quality filtering). NeMo Curator provides utilities to identify languages. The language identification is performed using fastText.\n",
    "\n",
    "It is worth mentioning that even though a preliminary language identification has been performed on rpv2 and we started with English-only dataset, fastText is more accurate so it can be used for a second pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7419a216-0dad-4d13-89ee-c3c1d009efa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator import ScoreFilter, Modify\n",
    "from nemo_curator.filters import FastTextLangId\n",
    "from nemo_curator.modifiers import UnicodeReformatter\n",
    "from nemo_curator.utils.file_utils import get_all_files_paths_under, separate_by_metadata\n",
    "\n",
    "# Language ID path\n",
    "language_output_path = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_resharded_with_id_lang\"))\n",
    "language_data_output_path = expand_outdir_and_mkdir(os.path.join(language_output_path,\"data\"))\n",
    "\n",
    "# Fasttext model path\n",
    "model_path = language_output_path\n",
    "\n",
    "# Define key in output .jsonl files to store the language information\n",
    "language_field = \"language\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82249135-d542-497f-896b-68c19297f434",
   "metadata": {},
   "source": [
    "Download the fastText model for langague detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7e6c9b-2aa3-4a8b-89ea-6dc4ca585b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-03 11:40:24--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.51, 3.163.189.96, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 131266198 (125M) [application/octet-stream]\n",
      "Saving to: ‘/home/neelesh/clean_c4_resharded_with_id_lang/lid.176.bin’\n",
      "\n",
      "lid.176.bin         100%[===================>] 125.18M  38.6MB/s    in 3.2s    \n",
      "\n",
      "2024-11-03 11:40:28 (38.6 MB/s) - ‘/home/neelesh/clean_c4_resharded_with_id_lang/lid.176.bin’ saved [131266198/131266198]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -P {model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca0e327-4055-48a9-8432-0aa0c21fb2b5",
   "metadata": {},
   "source": [
    "We will create an instance of Curator's `ScoreFilter` and use a helper function `separate_by_metadata` to separate the dataset into subfolders based on language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2684904-f73b-4a3b-a2f9-e4ce8725684c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for splitting language:1321.483018875122\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Load dataset\n",
    "id_data_dir = os.path.join(base_dir,\"../clean_c4_resharded_with_id\")\n",
    "input_dataset = DocumentDataset.read_json(id_data_dir, add_filename=True)\n",
    "\n",
    "# Define Language separation pipeline\n",
    "lang_filter = FastTextLangId(os.path.join(model_path,'lid.176.bin'))\n",
    "language_id_pipeline = ScoreFilter(\n",
    "    lang_filter, \n",
    "    score_field=language_field,\n",
    "    text_field=\"text\",\n",
    "    score_type='object'\n",
    ")\n",
    "filtered_dataset = language_id_pipeline(input_dataset)\n",
    "\n",
    "# drop the detailed classifier score\n",
    "filtered_dataset.df[language_field] = filtered_dataset.df[language_field].apply(\n",
    "    lambda score: score[1],meta = (language_field, 'object')\n",
    "    )\n",
    "\n",
    "# Split the dataset to corresponding language sub-folders\n",
    "language_stats = separate_by_metadata(\n",
    "    filtered_dataset.df, \n",
    "    language_data_output_path, \n",
    "    metadata_field=language_field\n",
    ").compute()\n",
    "\n",
    "print(f\"Time taken for splitting language:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a192a66-3886-41b4-8398-343ed58aa64c",
   "metadata": {},
   "source": [
    "The English dataset has 1,088,311,520 documents compared to 1,088,468,779 documents in the raw dataset. This is because the raw dataset is aleady detected and filtered to English dataset.\n",
    "\n",
    "We went from 91,217,230 examples down to 90858953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07216ded-5a61-46cc-b201-d816fb68d3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90858953"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dataset_path = os.path.join(base_dir,\"../clean_c4_resharded_with_id_lang/data/EN\")\n",
    "en_dataset = DocumentDataset.read_json(en_dataset_path, add_filename=True)\n",
    "\n",
    "len(en_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5dedde-a9bf-4f1f-a1ac-f5cc4a7aeeea",
   "metadata": {},
   "source": [
    "[Optional] Removing the ID'ed data to save disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7bfbc-e62c-4a00-abf0-786481c4eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {base_dir}/rpv2-2023-06-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a34f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ja_dataset_path = os.path.join(base_dir,\"rpv2-2023-06-language/data/JA\")\n",
    "# ja_dataset = DocumentDataset.read_json(ja_dataset_path, add_filename=True)\n",
    "\n",
    "# ja_dataset.df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a5a7f",
   "metadata": {},
   "source": [
    "## 4.4 Text cleaning\n",
    "\n",
    "Datasets may have improperly decoded unicode characters. Curator provides utilities to fix improperly decoded unicode characters based on the heuristics defined within the `ftfy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc6c27b-0369-4fe4-83da-2d2c70fc7898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    }
   ],
   "source": [
    "import nemo_curator\n",
    "from nemo_curator.modifiers import UnicodeReformatter\n",
    "\n",
    "en_dataset_path = os.path.join(base_dir,\"../clean_c4_resharded_with_id_lang/data/EN\")\n",
    "en_dataset = DocumentDataset.read_json(en_dataset_path, add_filename=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8775bb8-8ef8-4bd7-bdd3-7829cbd0b059",
   "metadata": {},
   "source": [
    "Curator offers uses the `modify` method with `UnicodeReformatter` for text cleaning. It requires the following arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6db96d-03fa-4085-a669-7170e4a3de6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make directory for cleaned dataset\n",
    "output_clean_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_en_cleaned\"))\n",
    "# specify text field name and file type\n",
    "input_text_field = \"text\"\n",
    "input_file_type = \"jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d8a85d-ab50-4917-9cf1-4dfa12bc1a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 1792 partitions\n",
      "Text cleaning took 3688.7079470157623 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# specify clearner\n",
    "cleaner = nemo_curator.Modify(\n",
    "    UnicodeReformatter(), \n",
    "    text_field=input_text_field\n",
    ")\n",
    "\n",
    "# clean dataset and write to disk\n",
    "cleaned_dataset = cleaner(en_dataset)\n",
    "cleaned_dataset.to_json(output_clean_dir, write_to_filename=True)\n",
    "print(f\"Text cleaning took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e304da3",
   "metadata": {},
   "source": [
    "[Optional] Removing intermediate data to save disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ed20eb-6ed9-481b-bf57-0ff6df27bf71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {base_dir}/rpv2-2023-06-language/data/EN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e16b97",
   "metadata": {},
   "source": [
    "# 5. Deduplication\n",
    "<a id=\"dedup\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ed8f1",
   "metadata": {},
   "source": [
    "## 5.1 Exact Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8120a1-100e-4527-b642-00e8ef298f1b",
   "metadata": {},
   "source": [
    "Exact dedup computes a hash for the raw text of each document. Documents with the same hash value will be exact duplicates and will be removed. Curator provides GPU-accelerated exact deduplication using Rapids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6dc1754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator.log import create_logger\n",
    "from nemo_curator.modules import ExactDuplicates\n",
    "\n",
    "# def pre_imports():\n",
    "#     import cudf  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6532bd31-af79-4d1e-bfb3-5bf432f55ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Workers = 128\n",
      "Pre imports complete\n"
     ]
    }
   ],
   "source": [
    "scheduler_address = os.getenv('SCHEDULER_ADDRESS')\n",
    "# gpu_client = get_client(scheduler_address=scheduler_address)\n",
    "# gpu_client = get_client(\n",
    "#     cluster_type=\"gpu\",\n",
    "#     n_workers=4,                             # One worker per GPU\n",
    "#     threads_per_worker=1,                    # One thread per worker\n",
    "#     rmm_pool_size=\"48GB\",                    # Memory pool size per GPU\n",
    "#     enable_spilling=True,                    # Allow spilling to host memory\n",
    "#     rmm_async=True,                          # Enable asynchronous RMM\n",
    "#     rmm_managed_memory=False,                # Prefer pool-based memory management\n",
    "#     protocol=\"ucx\",                          # Communication protocol\n",
    "#     set_torch_to_use_rmm=True,               # Use RMM if working with PyTorch\n",
    "# )\n",
    "cpu_client = get_client(\n",
    "    cluster_type=\"cpu\",\n",
    "    n_workers=128,                  # Number of workers, adjust to suit load (64 workers = 2 cores each)\n",
    "    threads_per_worker=1,          # Threads per worker for I/O-bound tasks or to maintain high CPU utilization\n",
    "    enable_spilling=True,          # Allow Dask to spill to disk when memory is tight\n",
    "    set_torch_to_use_rmm=False,    # Not applicable for CPU, but good to be explicit\n",
    "    memory_limit=\"16GB\",           # Memory per worker, allowing flexibility within 1TB\n",
    ")\n",
    "\n",
    "print(f\"Num Workers = {get_num_workers(cpu_client)}\", flush=True)\n",
    "\n",
    "# cpu_client.run(pre_imports)\n",
    "print(\"Pre imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d494c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 14:21:48,437 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48806 remote=tcp://127.0.0.1:45017>: Stream is closed\n",
      "2024-11-03 14:21:48,444 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48796 remote=tcp://127.0.0.1:45017>: Stream is closed\n",
      "2024-11-03 14:21:48,453 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48812 remote=tcp://127.0.0.1:45017>: Stream is closed\n",
      "2024-11-03 14:21:48,469 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48822 remote=tcp://127.0.0.1:45017>: Stream is closed\n",
      "2024-11-03 14:22:02,247 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,251 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,254 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,257 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,260 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,263 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,265 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,267 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,269 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,272 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,276 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,278 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,282 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,285 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,287 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,290 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,292 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,294 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,295 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,297 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,299 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,302 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,303 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,306 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,308 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,310 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,313 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,317 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,318 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,321 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,322 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,325 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,327 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,330 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,333 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,335 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,337 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,339 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,343 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,346 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,348 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,350 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,353 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,355 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,358 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,362 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,364 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,367 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,369 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,371 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,373 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,374 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,377 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,379 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,381 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,383 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,386 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,388 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,391 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,392 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,396 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,398 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,400 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:22:02,402 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cpu_client.cluster.close()\n",
    "cpu_client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9af962-b0d7-4012-a05a-c8287f8e62d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_dataset_path = os.path.join(base_dir,\"../clean_c4_en_cleaned\")\n",
    "log_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"logs\"))\n",
    "input_id_field = 'id'\n",
    "input_text_field = 'text'\n",
    "hash_method = 'md5'\n",
    "output_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_exact_dedup\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d139334-1db2-41db-910f-b2a478824e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact dedup took:187.99768805503845\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# Read the input dataset from the cleaned dataset dir\n",
    "input_dataset = DocumentDataset.read_json(cleaned_dataset_path)\n",
    "\n",
    "# Perform exact dedup\n",
    "exact_dups = ExactDuplicates(\n",
    "    logger=log_dir,\n",
    "    id_field=input_id_field,\n",
    "    text_field=input_text_field,\n",
    "    hash_method=hash_method,\n",
    "    cache_dir=output_dir,\n",
    ")\n",
    "duplicates = exact_dups(dataset=input_dataset)\n",
    "print(f\"Exact dedup took:{time.time()-t0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d1ee5-7d04-46a4-a480-8fc865d9a2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Exact deduplication found 97,327,867 duplicated documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7f66-4020-4f37-a8dc-200517dde329",
   "metadata": {},
   "source": [
    "Let's see the results of exact dedup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef1205a-981f-48d1-8e2e-53762e33a0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duplicates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m duplicates_df \u001b[38;5;241m=\u001b[39m \u001b[43mduplicates\u001b[49m\u001b[38;5;241m.\u001b[39mdf\n\u001b[1;32m      2\u001b[0m duplicates_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'duplicates' is not defined"
     ]
    }
   ],
   "source": [
    "duplicates_df = duplicates.df\n",
    "duplicates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df3643",
   "metadata": {},
   "source": [
    "We can sort the duplicate cluster by size and see that the largest cluster has 8 exact duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac54290-dc1d-4f60-b768-f162d338ca47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_hashes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61a3ade28229b37a315c102f982c6592</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24ca359fdcad574baf1bde55efbc2012</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524e08fdbd1cb1f50e7a22664326d6d</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dac7e27b45e1306c82ea3e2ce12bfd95</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87f8ae68fa14ce3f154f0a661e20477e</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count\n",
       "_hashes                                \n",
       "61a3ade28229b37a315c102f982c6592      8\n",
       "24ca359fdcad574baf1bde55efbc2012      6\n",
       "4524e08fdbd1cb1f50e7a22664326d6d      3\n",
       "dac7e27b45e1306c82ea3e2ce12bfd95      3\n",
       "87f8ae68fa14ce3f154f0a661e20477e      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_df.groupby('_hashes') \\\n",
    "             .agg({'id': 'count'}) \\\n",
    "             .rename(columns={'id': 'count'}) \\\n",
    "             .sort_values('count', ascending=False) \\\n",
    "             .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b38f5a6-6f48-4081-a717-fb9a1b5e9539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_hashes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4-train-0007801382</td>\n",
       "      <td>61a3ade28229b37a315c102f982c6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c4-train-0017258282</td>\n",
       "      <td>61a3ade28229b37a315c102f982c6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4-train-0018256270</td>\n",
       "      <td>61a3ade28229b37a315c102f982c6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c4-train-0028846946</td>\n",
       "      <td>61a3ade28229b37a315c102f982c6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c4-train-0044802347</td>\n",
       "      <td>61a3ade28229b37a315c102f982c6592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                           _hashes\n",
       "2   c4-train-0007801382  61a3ade28229b37a315c102f982c6592\n",
       "5   c4-train-0017258282  61a3ade28229b37a315c102f982c6592\n",
       "6   c4-train-0018256270  61a3ade28229b37a315c102f982c6592\n",
       "8   c4-train-0028846946  61a3ade28229b37a315c102f982c6592\n",
       "10  c4-train-0044802347  61a3ade28229b37a315c102f982c6592"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_group = duplicates_df[duplicates_df['_hashes'] == '61a3ade28229b37a315c102f982c6592'].compute()\n",
    "dup_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc83333-b19b-4335-92ef-6bcc29f3d7bf",
   "metadata": {},
   "source": [
    "[Optional] Verify if the documents with the same hash are exactly the same. We can use the ids from the cell output above (ids may change so revise the `dup_ids` as needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1a6018-dead-4d22-b496-87b5afe56e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for example duplicates with specific IDs took 64.67666721343994 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "dup_ids = ['c4-train-0007801382', 'c4-train-0017258282', 'c4-train-0018256270'] \n",
    "dup_examples = input_dataset.df[input_dataset.df['id'].isin(dup_ids)].compute()\n",
    "print(f\"Searching for example duplicates with specific IDs took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a62c96e2-cb2e-40ac-9f94-5aedb32e91c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13133</th>\n",
       "      <td>c4-train-0007801382</td>\n",
       "      <td>EN</td>\n",
       "      <td>网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...</td>\n",
       "      <td>1555944862000</td>\n",
       "      <td>http://www.5coney.com/2018/strength_0529/12.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>c4-train-0017258282</td>\n",
       "      <td>EN</td>\n",
       "      <td>网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...</td>\n",
       "      <td>1555944975000</td>\n",
       "      <td>http://www.5coney.com/2018/advantage_0528/1.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32792</th>\n",
       "      <td>c4-train-0018256270</td>\n",
       "      <td>EN</td>\n",
       "      <td>网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...</td>\n",
       "      <td>1555944384000</td>\n",
       "      <td>http://www.5coney.com/2018/advantage_0528/2.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id language  \\\n",
       "13133  c4-train-0007801382       EN   \n",
       "2547   c4-train-0017258282       EN   \n",
       "32792  c4-train-0018256270       EN   \n",
       "\n",
       "                                                    text      timestamp  \\\n",
       "13133  网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...  1555944862000   \n",
       "2547   网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...  1555944975000   \n",
       "32792  网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds...  1555944384000   \n",
       "\n",
       "                                                    url  \n",
       "13133  http://www.5coney.com/2018/strength_0529/12.html  \n",
       "2547   http://www.5coney.com/2018/advantage_0528/1.html  \n",
       "32792  http://www.5coney.com/2018/advantage_0528/2.html  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9876a2e1-ba4e-43a9-9cfe-5035c6e98ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example duplicate 1\n",
      "网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds1234567.com. All rights reserved.\n",
      "\n",
      "\n",
      "Example duplicate 2\n",
      "网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds1234567.com. All rights reserved.\n",
      "\n",
      "\n",
      "Example duplicate 3\n",
      "网站ICP备案序号:粤ICP备09046014号-1 Copyright ? 2015 ds1234567.com. All rights reserved.\n"
     ]
    }
   ],
   "source": [
    "print('Example duplicate 1\\n' + dup_examples.text.iloc[0])\n",
    "print('\\n\\nExample duplicate 2\\n' + dup_examples.text.iloc[1])\n",
    "print('\\n\\nExample duplicate 3\\n' + dup_examples.text.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f83e72-ac59-4b45-b0e6-be9144fe935e",
   "metadata": {},
   "source": [
    "Now, we will remove the exact duplicates and write the remaining dataset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aae6f4-bfea-479e-ba3b-dbbc3321ae87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1 files\n"
     ]
    }
   ],
   "source": [
    "input_dataset = DocumentDataset.read_json(cleaned_dataset_path, add_filename=True)\n",
    "duplicates = DocumentDataset.read_parquet(os.path.join(output_dir,\"_exact_duplicates.parquet\"))\n",
    "duplicates_df = duplicates.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d8c63a-fa8c-4b26-9978-d162fef8bd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to disk complete for 1792 partitions\n",
      "Removing exact duplicates took:171.1081485748291\n"
     ]
    }
   ],
   "source": [
    "output_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_exact_dedup_removed_final\"))\n",
    "\n",
    "t0 = time.time()\n",
    "docs_to_remove = duplicates_df.map_partitions(\n",
    "    lambda x: x[x._hashes.duplicated(keep=\"first\")]\n",
    ")\n",
    "\n",
    "# When there are few duplicates we can compute the results to a list and use `isin`.\n",
    "result = input_dataset.df[\n",
    "    ~input_dataset.df[input_id_field].isin(\n",
    "        docs_to_remove[input_id_field].compute()\n",
    "    )\n",
    "]\n",
    "\n",
    "write_to_disk(\n",
    "    result,\n",
    "    output_dir,\n",
    "    write_to_filename=True,\n",
    "    output_type='jsonl',\n",
    ")\n",
    "\n",
    "print(f\"Removing exact duplicates took:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad08cf-f114-4665-b03a-1778347ae636",
   "metadata": {},
   "source": [
    "We can see that exact dedup removed 4,264 documents and we now have 90,854,688 documents left in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37ceaa7-9d7c-49ab-a503-abe3be30861e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4265"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a018fbae-de99-4624-9027-de0b8b52e236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90854688"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d8d2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 14:41:06,643 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44484 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,654 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:43542 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,653 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44468 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,683 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:43558 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,697 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1253, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1452, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n",
      "2024-11-03 14:41:06,702 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:43534 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,713 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:37765', name: 55, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/tornado/ioloop.py\", line 939, in _run\n",
      "    await val\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1253, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1452, in connect\n",
      "    raise RuntimeError(\"ConnectionPool is closed\")\n",
      "RuntimeError: ConnectionPool is closed\n",
      "2024-11-03 14:41:06,710 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:43586 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,743 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44456 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,764 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44492 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,765 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44566 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,764 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44506 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,768 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44586 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44526 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,776 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44514 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,776 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44504 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,777 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44556 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,773 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44572 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,787 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44528 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,795 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44540 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:06,798 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 461, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/utils_comm.py\", line 440, in retry\n",
      "    return await coro()\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 1015, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44576 remote=tcp://127.0.0.1:37303>: Stream is closed\n",
      "2024-11-03 14:41:12,052 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,054 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,057 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,059 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,061 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,064 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,066 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,068 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,071 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,074 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,076 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,081 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,084 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,086 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,089 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n",
      "2024-11-03 14:41:12,091 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing\n"
     ]
    }
   ],
   "source": [
    "cpu_client.cluster.close()\n",
    "cpu_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9fb70d-51ea-48f9-8427-f1a42d049625",
   "metadata": {},
   "source": [
    "## 5.2 Fuzzy Deduplication\n",
    "\n",
    "Fuzzy deduplication aims to find near-duplicated documents in our dataset. Near-duplicated documents are common in web crawl data due to plagiarism and mirror sites. Removing them can help improve the quality of trained models. In many cases, we can skip exact dedup and just perform fuzzy dedup as it will also find the exact duplicates. Thus, we will start with the cleaned dataset for fuzzy dedup.\n",
    "\n",
    "Curator implements GPU-accelerated Fuzzy Deduplication based on minhash + LSH algorithm for finding similar documents across the dataset. Specifically, Fuzzy Deduplication include six steps:\n",
    "\n",
    "- Compute minhashes\n",
    "- Locality-Sensitive Hashing (LSH)\n",
    "- Map buckets\n",
    "- Jaccard shuffle\n",
    "- Jaccard compute\n",
    "- Connected components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750b1c02-2b37-474f-aaa2-2de86ac3a9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Workers = 4\n",
      "Pre imports complete\n"
     ]
    }
   ],
   "source": [
    "def pre_imports():\n",
    "    import cudf  # noqa: F401\n",
    "\n",
    "# scheduler_address = os.getenv('SCHEDULER_ADDRESS')\n",
    "# gpu_client = get_client(scheduler_address=scheduler_address)\n",
    "# gpu_client = get_client(\n",
    "#     cluster_type=\"gpu\",\n",
    "#     n_workers=4,                             # One worker per GPU\n",
    "#     threads_per_worker=32,                    # One thread per worker\n",
    "#     rmm_pool_size=\"48GB\",                    # Memory pool size per GPU\n",
    "#     enable_spilling=True,                    # Allow spilling to host memory\n",
    "#     rmm_async=True,                          # Enable asynchronous RMM\n",
    "#     rmm_managed_memory=False,                # Prefer pool-based memory management\n",
    "#     protocol=\"ucx\",                          # Communication protocol\n",
    "#     set_torch_to_use_rmm=True,               # Use RMM if working with PyTorch\n",
    "# )\n",
    "print(f\"Num Workers = {get_num_workers(gpu_client)}\", flush=True)\n",
    "\n",
    "gpu_client.run(pre_imports)\n",
    "print(\"Pre imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb279812-e11f-4e5e-bc38-cd4189201be9",
   "metadata": {},
   "source": [
    "### 5.2.1 Compute minhashes\n",
    "\n",
    "First, we will compute the minhash signature for each documents. For this purpose, each document will be represented by a set of n-grams. We will apply random hash functions on each element of the set. The minimum hash value generated by each hash function will be recorded and becomes a component of the MinHash signature. Thus, the length of the minhash signature will be the same as the number of hash functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad04e90-a1b6-4881-a29a-dc0c63b026bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator import MinHash\n",
    "\n",
    "input_data_dir = os.path.join(base_dir,\"../clean_c4_en_cleaned\")\n",
    "seed = 42\n",
    "minhash_length = 260\n",
    "char_ngram = 5\n",
    "log_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"logs\"))\n",
    "id_field = 'id'\n",
    "text_field = 'text'\n",
    "minshah_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_minhash\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a42f11d4-3b53-4d64-8f47-dd834f6e1312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    }
   ],
   "source": [
    "files = get_all_files_paths_under(root=input_data_dir, recurse_subdirectories=False)\n",
    "files = [f for f in files if f.endswith(\".jsonl\")]\n",
    "df = read_data(\n",
    "    files,\n",
    "    file_type=\"jsonl\",\n",
    "    backend=\"cudf\",\n",
    "    files_per_partition=1,\n",
    "    add_filename=False,\n",
    ")[[id_field, text_field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897b88bf-f49f-46a0-b19d-c3688cb056f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-178816' coro=<Client._gather.<locals>.wait() done, defined at /home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing minhashes took:314.1223084926605\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run MinHash() on input data\n",
    "minhasher = MinHash(\n",
    "    seed=seed,\n",
    "    num_hashes=minhash_length,\n",
    "    char_ngrams=char_ngram,\n",
    "    use_64bit_hash=False,\n",
    "    logger=log_dir,\n",
    "    id_field=id_field,\n",
    "    text_field=text_field,\n",
    "    cache_dir=minshah_output_dir\n",
    ")\n",
    "\n",
    "result = minhasher(DocumentDataset(df)).df\n",
    "\n",
    "print(f\"Computing minhashes took:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a198426-29d2-4e60-9468-e2839d634d18",
   "metadata": {},
   "source": [
    "We can see some example outputs from the minhash computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5358f6-12c5-4ffb-ad0d-19af893670ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_minhash_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4-train-0000000000</td>\n",
       "      <td>[30032382, 157261, 5008033, 4311555, 19755091,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4-train-0000000001</td>\n",
       "      <td>[511522, 1015487, 2320335, 651428, 1906819, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4-train-0000000002</td>\n",
       "      <td>[15994705, 6370213, 15559465, 9740304, 6210120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4-train-0000000003</td>\n",
       "      <td>[1449615, 1872293, 3654170, 452331, 780352, 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4-train-0000000004</td>\n",
       "      <td>[6685476, 2415781, 1112347, 742646, 6898911, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                 _minhash_signature\n",
       "0  c4-train-0000000000  [30032382, 157261, 5008033, 4311555, 19755091,...\n",
       "1  c4-train-0000000001  [511522, 1015487, 2320335, 651428, 1906819, 14...\n",
       "2  c4-train-0000000002  [15994705, 6370213, 15559465, 9740304, 6210120...\n",
       "3  c4-train-0000000003  [1449615, 1872293, 3654170, 452331, 780352, 39...\n",
       "4  c4-train-0000000004  [6685476, 2415781, 1112347, 742646, 6898911, 4..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27e094-c097-48e3-aeae-446acc01b965",
   "metadata": {},
   "source": [
    "### 5.2.2 Minhash LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1c210-2670-48b7-90d7-8105e274e1a8",
   "metadata": {},
   "source": [
    "LSH() implements LSH algorithm which includes the following steps:\n",
    "\n",
    "- Divide the minhash signature array into X different portions.\n",
    "\n",
    "- For each portions, hash the minhash values into buckets. One document will be assigned to X buckets.\n",
    "\n",
    "- Documents within the same bucket will be deemed similar. Since every document will be assigned X buckets and as long as two documents share 1 or more buckets they are deemed similar, the result of LSH will have more false positive as compared to false negative. The false positive cases will be filtered in following modules, namely jaccard compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b62629-6d54-43ce-8995-49a89d89859f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator import LSH\n",
    "from nemo_curator.utils.fuzzy_dedup_utils.id_mapping import convert_str_id_to_int\n",
    "\n",
    "lsh_input_dir = os.path.join(base_dir,\"../clean_c4_minhash\")\n",
    "id_field = 'id'\n",
    "output_bucket_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_fuzzy_dedup\"))\n",
    "num_bands = 20\n",
    "buckets_per_shuffle = 1\n",
    "minhash_field = '_minhash_signature'\n",
    "minhash_length = 260\n",
    "log_dir = os.path.join(base_dir, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ccb7591-e5ef-482a-b226-a612641f90d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSH took 776.1493239402771 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#Load MinHash output\n",
    "df = dask_cudf.read_parquet(lsh_input_dir, blocksize=\"2GB\", aggregate_files=True)\n",
    "df = df.map_partitions(\n",
    "    convert_str_id_to_int,\n",
    "    id_column=id_field,\n",
    "    meta=cudf.DataFrame(\n",
    "        {minhash_field: [[1, 2, 3]], \"doc_id\": [1], \"dataset_id\": np.uint32(1)}\n",
    "    ),\n",
    ")\n",
    "\n",
    "lsh = LSH(\n",
    "    cache_dir=output_bucket_dir,\n",
    "    num_hashes=minhash_length,\n",
    "    num_buckets=num_bands,\n",
    "    buckets_per_shuffle=buckets_per_shuffle,\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"],\n",
    "    minhash_field=minhash_field,\n",
    "    logger=log_dir,\n",
    ")\n",
    "\n",
    "lsh_result = lsh(DocumentDataset(df))\n",
    "print(f\"LSH took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d14ba2f-cfb8-448e-9bb8-34af6005ba15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>_bucket_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>39975608</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>36113741</td>\n",
       "      <td>11309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>42465749</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>66092294</td>\n",
       "      <td>6835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>49010978</td>\n",
       "      <td>13088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id    doc_id  _bucket_id\n",
       "0  2191958705  39975608         164\n",
       "1  2191958705  36113741       11309\n",
       "2  2191958705  42465749        2525\n",
       "3  2191958705  66092294        6835\n",
       "4  2191958705  49010978       13088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_result.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9dbc9",
   "metadata": {},
   "source": [
    "### 5.2.3 Map Buckets\n",
    "\n",
    "After performing LSH, we processed each bucket and calculated an approximation of the all-pairs Jaccard\n",
    "similarity in order to remove false positive duplicates introduced by LSH. For this purpose, we will randomly sample n \"anchor\" documents within each buckets and calculate the Jaccard similarity with everything remaining in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7985cf1a-9d88-4844-8ce4-e68d9792118c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator.modules.fuzzy_dedup import _MapBuckets\n",
    "from nemo_curator.utils.fuzzy_dedup_utils.io_utils import (\n",
    "    get_bucket_ddf_from_parquet_path,\n",
    "    get_text_ddf_from_json_path_with_blocksize,\n",
    ")\n",
    "\n",
    "input_data_paths = [os.path.join(base_dir,\"../clean_c4_en_cleaned\")]\n",
    "num_files = None\n",
    "text_ddf_blocksize = 256 #The block size for chunking jsonl files for text ddf in mb\n",
    "id_field = 'id'\n",
    "text_field = 'text'\n",
    "input_bucket_path = os.path.join(base_dir,\"../clean_c4_fuzzy_dedup/_buckets.parquet\")\n",
    "input_bucket_field = '_bucket_id'\n",
    "shuffle_type ='tasks'\n",
    "log_dir = os.path.join(base_dir, \"logs\")\n",
    "output_anchor_docs_with_bk_path = expand_outdir_and_mkdir(os.path.join(base_dir,\"../clean_c4_fuzzy_dedup/anchor_docs_with_bk.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f94be7c9-27ea-4f1f-8a8f-05a866eafac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files being read for jaccard calculation = 1792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddf_text.npartitions  = 896\n"
     ]
    }
   ],
   "source": [
    "# Read .jsonl input data\n",
    "ddf_text = get_text_ddf_from_json_path_with_blocksize(\n",
    "    input_data_paths=input_data_paths,\n",
    "    num_files=num_files,\n",
    "    blocksize=text_ddf_blocksize,\n",
    "    id_column=id_field,\n",
    "    text_column=text_field,\n",
    ")\n",
    "\n",
    "print(f\"ddf_text.npartitions  = {ddf_text.npartitions}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0700327-5171-4673-8ded-c9f43492f582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ddf_bk partitions = 4\n",
      "Mapping Bucket took 71.95588207244873 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "num_workers = get_num_workers(gpu_client)\n",
    "\n",
    "# Read \"_buckets.parquet\"\n",
    "ddf_bk = get_bucket_ddf_from_parquet_path(\n",
    "    input_bucket_path=input_bucket_path, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "#Run _MapBuckets()\n",
    "map_buckets = _MapBuckets(\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"], \n",
    "    bucket_field=input_bucket_field, \n",
    "    logger=log_dir,\n",
    "    text_field=text_field,\n",
    ")\n",
    "\n",
    "ddf_anchor_docs_with_bk = map_buckets.map_buckets_with_anchors(\n",
    "    documents_df=ddf_text, \n",
    "    buckets_df=ddf_bk, \n",
    "    shuffle_type=shuffle_type\n",
    ")\n",
    "\n",
    "#Write to disk\n",
    "ddf_anchor_docs_with_bk.to_parquet(\n",
    "    output_anchor_docs_with_bk_path, \n",
    "    write_index=False\n",
    ")\n",
    "\n",
    "print(f\"Mapping Bucket took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a986f76-191e-436d-9df3-bb68dc78d365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>anchor_1_dataset_id</th>\n",
       "      <th>anchor_1_doc_id</th>\n",
       "      <th>anchor_0_dataset_id</th>\n",
       "      <th>anchor_0_doc_id</th>\n",
       "      <th>_output_partition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>80650180</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>82126513</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>5644139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>37749971</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>37749971</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>40615424</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>43538852</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>78393372</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>43538852</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>4999544</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>50915758</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>90667015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2191958705</td>\n",
       "      <td>49792759</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>78927539</td>\n",
       "      <td>2191958705</td>\n",
       "      <td>86045229</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id    doc_id  anchor_1_dataset_id  anchor_1_doc_id  \\\n",
       "0  2191958705  80650180           2191958705         82126513   \n",
       "1  2191958705  37749971           2191958705         37749971   \n",
       "2  2191958705  43538852           2191958705         78393372   \n",
       "3  2191958705   4999544           2191958705         50915758   \n",
       "4  2191958705  49792759           2191958705         78927539   \n",
       "\n",
       "   anchor_0_dataset_id  anchor_0_doc_id  _output_partition_id  \n",
       "0           2191958705          5644139                     4  \n",
       "1           2191958705         40615424                    11  \n",
       "2           2191958705         43538852                    10  \n",
       "3           2191958705         90667015                     6  \n",
       "4           2191958705         86045229                     5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_anchor_docs_with_bk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e90363-ebfe-48e2-8f7c-ff7ef27c97d5",
   "metadata": {},
   "source": [
    "### 5.2.4 Jaccard Shuffle\n",
    "\n",
    "We shuffle the documents within the dataset based on their bucket assignments, essentially distributing similar documents across different partitions or workers, enabling efficient parallel processing and deduplication in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d7184d-4ca5-4b49-85b4-1264056f5c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator.modules.fuzzy_dedup import _Shuffle\n",
    "\n",
    "log_dir = os.path.join(base_dir, \"logs\")\n",
    "input_anchor_docs_with_bk_path = os.path.join(base_dir,\"../clean_c4_fuzzy_dedup/anchor_docs_with_bk.parquet\")\n",
    "output_shuffled_docs_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/shuffled_docs.parquet\")\n",
    ")\n",
    "bucket_mapping_ddf_blocksize = 256\n",
    "parts_per_worker = 16\n",
    "bucket_parts_per_worker = 256\n",
    "id_field = 'id'\n",
    "text_field = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07894e81-6cdc-4292-951a-977b220fbd81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started processing bucket-map partitions 0 through 4 of 4\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2995018 rows to disk\n",
      "Text-df partition  64/896 completed in 10.766233205795288\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 3000449 rows to disk\n",
      "Text-df partition  128/896 completed in 10.238612651824951\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2988926 rows to disk\n",
      "Text-df partition  192/896 completed in 9.267656803131104\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2991151 rows to disk\n",
      "Text-df partition  256/896 completed in 9.227095365524292\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2986838 rows to disk\n",
      "Text-df partition  320/896 completed in 8.993366956710815\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2993451 rows to disk\n",
      "Text-df partition  384/896 completed in 8.884929895401001\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2989090 rows to disk\n",
      "Text-df partition  448/896 completed in 8.773952007293701\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2980905 rows to disk\n",
      "Text-df partition  512/896 completed in 8.948848724365234\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2998235 rows to disk\n",
      "Text-df partition  576/896 completed in 8.89646029472351\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2990212 rows to disk\n",
      "Text-df partition  640/896 completed in 9.619351387023926\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2995111 rows to disk\n",
      "Text-df partition  704/896 completed in 8.777507066726685\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2987013 rows to disk\n",
      "Text-df partition  768/896 completed in 9.577385425567627\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2982458 rows to disk\n",
      "Text-df partition  832/896 completed in 8.684473752975464\n",
      "Using 64 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 2996381 rows to disk\n",
      "Text-df partition  896/896 completed in 8.992177963256836\n",
      "Bucket partition  4/4 completed in 129.6961236000061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:09<00:00, 129.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Shuffle took 129.80706119537354 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "shuffle = _Shuffle(\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"],\n",
    "    text_field=text_field,\n",
    "    int_to_str_id=id_field,\n",
    "    logger=log_dir,\n",
    ")\n",
    "\n",
    "shuffle.shuffle_docs_on_buckets(\n",
    "    documents_df=ddf_text,\n",
    "    bucket_w_anchors_path=input_anchor_docs_with_bk_path,\n",
    "    output_shuffled_docs_path=output_shuffled_docs_path,\n",
    "    bucket_mapping_df_blocksize=bucket_mapping_ddf_blocksize,\n",
    "    parts_per_worker=parts_per_worker,\n",
    "    bucket_parts_per_worker=bucket_parts_per_worker,\n",
    "    partition_on=\"_output_partition_id\",\n",
    ")\n",
    "\n",
    "print(f\"Jaccard Shuffle took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26739f23-47f1-4e11-ac49-82920f534495",
   "metadata": {},
   "source": [
    "We can visualize the jaccard shuffle results for a single partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3576685a-c3d8-4950-bac3-5412e9f876d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>_text_bytes</th>\n",
       "      <th>id</th>\n",
       "      <th>anchor_0_id</th>\n",
       "      <th>anchor_1_id</th>\n",
       "      <th>_output_partition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are able to rely on Bathroom Toilet Guys t...</td>\n",
       "      <td>2347</td>\n",
       "      <td>2191958705-2610117</td>\n",
       "      <td>2191958705-26983035</td>\n",
       "      <td>2191958705-40014867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are able to trust in Building Contractor T...</td>\n",
       "      <td>2655</td>\n",
       "      <td>2191958705-5361227</td>\n",
       "      <td>2191958705-42968742</td>\n",
       "      <td>2191958705-36434720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A super premium .Com domain name from DomainMa...</td>\n",
       "      <td>2937</td>\n",
       "      <td>2191958705-3201346</td>\n",
       "      <td>2191958705-70134761</td>\n",
       "      <td>2191958705-55782143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prefab Building Guys is here for your goals co...</td>\n",
       "      <td>2339</td>\n",
       "      <td>2191958705-6065219</td>\n",
       "      <td>2191958705-54311928</td>\n",
       "      <td>2191958705-6602398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're able to depend on 2 Person Hot Tub Guys...</td>\n",
       "      <td>2462</td>\n",
       "      <td>2191958705-2088686</td>\n",
       "      <td>2191958705-65642188</td>\n",
       "      <td>2191958705-86688878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  _text_bytes  \\\n",
       "0  You are able to rely on Bathroom Toilet Guys t...         2347   \n",
       "1  You are able to trust in Building Contractor T...         2655   \n",
       "2  A super premium .Com domain name from DomainMa...         2937   \n",
       "3  Prefab Building Guys is here for your goals co...         2339   \n",
       "4  You're able to depend on 2 Person Hot Tub Guys...         2462   \n",
       "\n",
       "                   id          anchor_0_id          anchor_1_id  \\\n",
       "0  2191958705-2610117  2191958705-26983035  2191958705-40014867   \n",
       "1  2191958705-5361227  2191958705-42968742  2191958705-36434720   \n",
       "2  2191958705-3201346  2191958705-70134761  2191958705-55782143   \n",
       "3  2191958705-6065219  2191958705-54311928   2191958705-6602398   \n",
       "4  2191958705-2088686  2191958705-65642188  2191958705-86688878   \n",
       "\n",
       "  _output_partition_id  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_shuffle_res = dd.read_parquet(os.path.join(output_shuffled_docs_path,\"_output_partition_id=0\"))\n",
    "jaccard_shuffle_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80309eef-733a-4926-875f-cb94bbb4d8fa",
   "metadata": {},
   "source": [
    "### 5.2.5 Jaccard Compute\n",
    "\n",
    "Now we have the jaccard pairs sampled, we can compute the Jaccard similarity score for all pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573dccf7-2e23-4aae-a3ec-2b9e1a42d97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator.modules.fuzzy_dedup import JaccardSimilarity\n",
    "\n",
    "id_field = 'id'\n",
    "text_field = 'text'\n",
    "ngram_size = 5\n",
    "shuffled_docs_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/shuffled_docs.parquet\")\n",
    "jaccard_results_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/jaccard_similarity_results.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a24fe-8229-48bc-89f7-32f2b93f4f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Computing+Writing took 18.565584421157837 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "jaccard = JaccardSimilarity(\n",
    "    id_field=id_field,\n",
    "    text_field=text_field,\n",
    "    anchor_id_fields=[f\"anchor_{i}_{id_field}\" for i in range(2)],\n",
    "    ngram_width=ngram_size,\n",
    ")\n",
    "\n",
    "# Run actual computation\n",
    "result_df = jaccard.jaccard_compute(shuffled_docs_path)\n",
    "\n",
    "result_df.to_parquet(\n",
    "    jaccard_results_path,\n",
    "    write_index=False,\n",
    "    write_metadata_file=False,\n",
    ")\n",
    "\n",
    "print(f\"Jaccard Computing+Writing took {time.time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbebed9d-d920-4b8e-8c88-48f1906c46e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>id_y</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2191958705-17148786</td>\n",
       "      <td>2191958705-9519602</td>\n",
       "      <td>0.809187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191958705-9327883</td>\n",
       "      <td>2191958705-7073840</td>\n",
       "      <td>0.908163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2191958705-8357724</td>\n",
       "      <td>2191958705-9443292</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2191958705-15262553</td>\n",
       "      <td>2191958705-9443292</td>\n",
       "      <td>0.849854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2191958705-19226246</td>\n",
       "      <td>2191958705-12862039</td>\n",
       "      <td>0.923301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_x                 id_y   jaccard\n",
       "0  2191958705-17148786   2191958705-9519602  0.809187\n",
       "1   2191958705-9327883   2191958705-7073840  0.908163\n",
       "2   2191958705-8357724   2191958705-9443292  0.733333\n",
       "3  2191958705-15262553   2191958705-9443292  0.849854\n",
       "4  2191958705-19226246  2191958705-12862039  0.923301"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_compute_res = dd.read_parquet(jaccard_results_path)\n",
    "jaccard_compute_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e1287-bd19-4728-a4c8-b92b39ca1fcc",
   "metadata": {},
   "source": [
    "### 5.2.6 Connected Component\n",
    "\n",
    "After all buckets were processed and duplicates (at the threshold) were approximately discovered,\n",
    "we constructed a sparse document graph and found the connected components therein (using scipy). Each\n",
    "connected component represents a set of documents that we consider similar enough to be duplicates, and\n",
    "from which we select a single representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2781a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_curator.modules.fuzzy_dedup import ConnectedComponents\n",
    "\n",
    "cache_dir = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/new-cc-cache\")\n",
    ")\n",
    "jaccard_pairs_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/jaccard_similarity_results.parquet\")\n",
    "id_field = 'id'\n",
    "jaccard_threshold = 0.8\n",
    "output_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/connected_components.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bee85f3-5477-4b9c-b606-7bbbefbe6cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Component took 23.1136314868927 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "components_stage = ConnectedComponents(\n",
    "    cache_dir=cache_dir,\n",
    "    jaccard_pairs_path=jaccard_pairs_path,\n",
    "    id_column=id_field,\n",
    "    # convert_str_ids=True,\n",
    "\n",
    "    jaccard_threshold=jaccard_threshold,\n",
    ")\n",
    "components_stage.cc_workflow(output_path=output_path)\n",
    "print(f\"Connected Component took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aeb619-3fab-4a18-b582-bccae3eefd17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-47525' coro=<_listener_handler_coroutine() done, defined at /home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/ucp/core.py:140> exception=RuntimeError('<distributed._async_taskgroup.AsyncTaskGroup object at 0x7fd4b818aa40> is bound to a different event loop')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/ucp/core.py\", line 190, in _listener_handler_coroutine\n",
      "    await func(ep)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/comm/ucx.py\", line 526, in serve_forever\n",
      "    await self.comm_handler(ucx)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/core.py\", line 732, in handle_comm\n",
      "    self._ongoing_background_tasks.call_soon(self._handle_comm, comm)\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/_async_taskgroup.py\", line 90, in call_soon\n",
      "    task = self._get_loop().create_task(afunc(*args, **kwargs))\n",
      "  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/distributed/_async_taskgroup.py\", line 32, in _get_loop\n",
      "    raise RuntimeError(f\"{self!r} is bound to a different event loop\")\n",
      "RuntimeError: <distributed._async_taskgroup.AsyncTaskGroup object at 0x7fd4b818aa40> is bound to a different event loop\n"
     ]
    }
   ],
   "source": [
    "# from nemo_curator.modules.fuzzy_dedup import ConnectedComponents\n",
    "\n",
    "# # start a local GPU dask cluster with 4 GPUs \n",
    "# gpu_client = get_client(\n",
    "#     cluster_type=\"gpu\",\n",
    "#     n_workers=4,                             # One worker per GPU\n",
    "#     threads_per_worker=1,                    # One thread per worker\n",
    "#     rmm_pool_size=\"48GB\",                    # Memory pool size per GPU\n",
    "#     enable_spilling=True,                    # Allow spilling to host memory\n",
    "#     rmm_async=True,                          # Enable asynchronous RMM\n",
    "#     rmm_managed_memory=False,                # Prefer pool-based memory management\n",
    "#     protocol=\"ucx\",                          # Communication protocol\n",
    "#     set_torch_to_use_rmm=True,               # Use RMM if working with PyTorch\n",
    "# )\n",
    "\n",
    "\n",
    "# # cache_dir = expand_outdir_and_mkdir(\n",
    "# #     os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/cc-cache\")\n",
    "# # )\n",
    "# # jaccard_pairs_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/jaccard_similarity_results.parquet\")\n",
    "# # id_field = 'id'\n",
    "# # jaccard_threshold = 0.8\n",
    "# # output_path = expand_outdir_and_mkdir(\n",
    "# #     os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/connected_components.parquet\")\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dd2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize connected components output \n",
    "cc_output = dd.read_parquet(output_path)\n",
    "cc_output.head()\n",
    "len(cc_output)\n",
    "output_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/connected_components.parquet\")\n",
    "cc_result = dask_cudf.read_parquet(output_path, split_row_groups=False).repartition(npartitions=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15214dcf-ff49-439e-b3d7-d8666d081027",
   "metadata": {},
   "source": [
    "Let's check the results of connected components step. We can see that 239,037,733 are identified as duplicates to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e8126d-af15-4182-98cd-10df06e9778e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `alt_split_ids`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nRuntimeError('CUDF failure at: /__w/cudf/cudf/cpp/src/strings/strings_column_view.cpp:27: strings_column_view only supports strings')\n\nTraceback:\n---------\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 4025, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/tmp/ipykernel_1927870/497653039.py\", line 5, in alt_split_ids\n    df['dataset_id'] = df['id'].str.rsplit('-', n=1).str[0]\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py\", line 189, in __getitem__\n    return self.get(key)\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py\", line 2314, in get\n    return self._return_or_inplace(libstrings.get(self._column, i))\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/contextlib.py\", line 79, in inner\n    return func(*args, **kwds)\n  File \"substring.pyx\", line 79, in cudf._lib.strings.substring.get\n  File \"slice.pyx\", line 18, in pylibcudf.strings.slice.__pyx_fuse_1slice_strings\n  File \"slice.pyx\", line 92, in pylibcudf.strings.slice.slice_strings\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/utils.py:193\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py:4025\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[0;32m-> 4025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 5\u001b[0m, in \u001b[0;36malt_split_ids\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malt_split_ids\u001b[39m(df):\n\u001b[0;32m----> 5\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py:189\u001b[0m, in \u001b[0;36mStringMethods.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py:2314\u001b[0m, in \u001b[0;36mStringMethods.get\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   2273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;124;03mExtract element from each component at specified position.\u001b[39;00m\n\u001b[1;32m   2275\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;124;03mdtype: object\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_inplace(\u001b[43mlibstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msubstring.pyx:79\u001b[0m, in \u001b[0;36mcudf._lib.strings.substring.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mslice.pyx:18\u001b[0m, in \u001b[0;36mpylibcudf.strings.slice.__pyx_fuse_1slice_strings\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mslice.pyx:92\u001b[0m, in \u001b[0;36mpylibcudf.strings.slice.slice_strings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDF failure at: /__w/cudf/cudf/cpp/src/strings/strings_column_view.cpp:27: strings_column_view only supports strings",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m----> 9\u001b[0m cc_result \u001b[38;5;241m=\u001b[39m \u001b[43mcc_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43malt_split_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Set 'group' as the index and shuffle to ensure all same 'group' values are in the same partition\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cc_result \u001b[38;5;241m=\u001b[39m cc_result\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtasks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py:1103\u001b[0m, in \u001b[0;36mFrameBase.map_partitions\u001b[0;34m(self, func, meta, enforce_metadata, transform_divisions, clear_divisions, align_dataframes, parent_meta, *args, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@insert_meta_param_description\u001b[39m(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_partitions\u001b[39m(\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    990\u001b[0m ):\n\u001b[1;32m    991\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply a Python function to each partition\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m    None as the division.\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_dataframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_dataframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py:6273\u001b[0m, in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, clear_divisions, align_dataframes, parent_meta, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m   6260\u001b[0m new_expr \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mMapPartitions(\n\u001b[1;32m   6261\u001b[0m     args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   6262\u001b[0m     func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6271\u001b[0m     \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m   6272\u001b[0m )\n\u001b[0;32m-> 6273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_expr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py:4799\u001b[0m, in \u001b[0;36mnew_collection\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_collection\u001b[39m(expr):\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4799\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   4800\u001b[0m     expr\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_collection_type(meta)(expr)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py:630\u001b[0m, in \u001b[0;36mMapPartitions._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    629\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_meta_map_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py:4039\u001b[0m, in \u001b[0;36m_get_meta_map_partitions\u001b[0;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m no_default:\n\u001b[1;32m   4036\u001b[0m     \u001b[38;5;66;03m# Use non-normalized kwargs here, as we want the real values (not\u001b[39;00m\n\u001b[1;32m   4037\u001b[0m     \u001b[38;5;66;03m# delayed values)\u001b[39;00m\n\u001b[1;32m   4038\u001b[0m     a \u001b[38;5;241m=\u001b[39m [meta_nonempty(arg\u001b[38;5;241m.\u001b[39m_meta) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Expr) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m-> 4039\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43m_emulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mudf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4040\u001b[0m     meta_is_emulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py:4024\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_emulate\u001b[39m(func, \u001b[38;5;241m*\u001b[39margs, udf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   4020\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4021\u001b[0m \u001b[38;5;124;03m    Apply a function using args / kwargs. If arguments contain dd.DataFrame /\u001b[39;00m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;124;03m    dd.Series, using internal cache (``_meta``) for calculation\u001b[39;00m\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[1;32m   4025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m_extract_meta(args, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_extract_meta(kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/utils.py:214\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    205\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error is below:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    213\u001b[0m msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m funcname \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(e), tb)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `alt_split_ids`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nRuntimeError('CUDF failure at: /__w/cudf/cudf/cpp/src/strings/strings_column_view.cpp:27: strings_column_view only supports strings')\n\nTraceback:\n---------\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/utils.py\", line 193, in raise_on_meta_error\n    yield\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 4025, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/tmp/ipykernel_1927870/497653039.py\", line 5, in alt_split_ids\n    df['dataset_id'] = df['id'].str.rsplit('-', n=1).str[0]\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py\", line 189, in __getitem__\n    return self.get(key)\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/cudf/core/column/string.py\", line 2314, in get\n    return self._return_or_inplace(libstrings.get(self._column, i))\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/contextlib.py\", line 79, in inner\n    return func(*args, **kwds)\n  File \"substring.pyx\", line 79, in cudf._lib.strings.substring.get\n  File \"slice.pyx\", line 18, in pylibcudf.strings.slice.__pyx_fuse_1slice_strings\n  File \"slice.pyx\", line 92, in pylibcudf.strings.slice.slice_strings\n"
     ]
    }
   ],
   "source": [
    "# output_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/connected_components.parquet\")\n",
    "# cc_result = dask_cudf.read_parquet(output_path, split_row_groups=True).repartition(npartitions=1)\n",
    "\n",
    "# def alt_split_ids(df):\n",
    "#     df['dataset_id'] = df['id'].str.rsplit('-', n=1).str[0]\n",
    "#     df['doc_id'] = df['id'].str.rsplit('-', n=1).str[1]\n",
    "#     return df\n",
    "\n",
    "# cc_result = cc_result.map_partitions(\n",
    "#     alt_split_ids,\n",
    "# )\n",
    "\n",
    "# # Set 'group' as the index and shuffle to ensure all same 'group' values are in the same partition\n",
    "# cc_result = cc_result.set_index('group', shuffle='tasks')\n",
    "# # Define a function to assign cumulative counts and filter duplicates\n",
    "# def assign_cumcount(df):\n",
    "#     df['cumcount'] = df.groupby(level=0).cumcount()\n",
    "#     df = df[df['cumcount'] >= 1]\n",
    "#     df = df.drop(columns=['cumcount'])\n",
    "#     return df\n",
    "\n",
    "# # Find duplicates by applying the function to each partition\n",
    "# docs_to_remove = cc_result.map_partitions(assign_cumcount, meta=cc_result)\n",
    "\n",
    "# # Reset the index\n",
    "# docs_to_remove = docs_to_remove.reset_index()\n",
    "\n",
    "# print(\"num of docs to remove =\", len(docs_to_remove))\n",
    "\n",
    "# docs_to_remove = docs_to_remove[[\"dataset_id\", \"doc_id\"]]\n",
    "# docs_to_remove = docs_to_remove.rename(columns={\"dataset_id\":\"to_remove_dataset_id\", \"doc_id\":\"to_remove_doc_id\"})\n",
    "# docs_to_remove = docs_to_remove.reset_index(drop=True).persist()\n",
    "# _ = wait(docs_to_remove)\n",
    "# del _ \n",
    "\n",
    "# print(\"num of docs to remove =\", len(docs_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d28c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of docs to remove = 4252657\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(base_dir, \"../clean_c4_fuzzy_dedup/connected_components.parquet\")\n",
    "cc_result = dask_cudf.read_parquet(output_path, split_row_groups=False).repartition(npartitions=1)\n",
    "\n",
    "# Set 'group' as the index and shuffle to ensure all same 'group' values are in the same partition\n",
    "cc_result = cc_result.set_index('group', shuffle='tasks')\n",
    "\n",
    "# Define a function to assign cumulative counts and filter duplicates\n",
    "def assign_cumcount(df):\n",
    "    df['cumcount'] = df.groupby(level=0).cumcount()\n",
    "    df = df[df['cumcount'] >= 1]\n",
    "    df = df.drop(columns=['cumcount'])\n",
    "    return df\n",
    "\n",
    "# Find duplicates by applying the function to each partition\n",
    "docs_to_remove = cc_result.map_partitions(assign_cumcount, meta=cc_result)\n",
    "\n",
    "# Reset the index\n",
    "docs_to_remove = docs_to_remove.reset_index()\n",
    "\n",
    "# docs_to_remove = docs_to_remove[[\"dataset_id\", \"doc_id\"]]\n",
    "docs_to_remove = docs_to_remove[[\"id\"]]\n",
    "# docs_to_remove = docs_to_remove.rename(columns={\"dataset_id\":\"to_remove_dataset_id\", \"doc_id\":\"to_remove_doc_id\"})\n",
    "docs_to_remove = docs_to_remove.rename(columns={\"id\":\"to_remove_id\"})\n",
    "docs_to_remove = docs_to_remove.reset_index(drop=True).persist()\n",
    "_ = wait(docs_to_remove)\n",
    "del _ \n",
    "\n",
    "print(\"num of docs to remove =\", len(docs_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa04bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to_remove_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2191958705-75949870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191958705-49217365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2191958705-59970680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2191958705-39328485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2191958705-52628412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          to_remove_id\n",
       "0  2191958705-75949870\n",
       "1  2191958705-49217365\n",
       "2  2191958705-59970680\n",
       "3  2191958705-39328485\n",
       "4  2191958705-52628412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_to_remove.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ee0b5-f2dd-4d34-917f-56f4211a36fe",
   "metadata": {},
   "source": [
    "We can examine the size of the duplicate clusters. The largest cluster has 775,379 near duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae7f166-836a-4c21-bff2-7453254956b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown aggregate lambda",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# cc_grouped = cc_result.groupby('group').agg({'doc_id': 'count'}).rename(columns={'doc_id': 'count'}).sort_values('count', ascending=False).compute()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cc_grouped \u001b[38;5;241m=\u001b[39m \u001b[43mcc_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgroup\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnunique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m      6\u001b[0m cc_grouped\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:1948\u001b[0m, in \u001b[0;36mGroupBy.agg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_cudf/expr/_groupby.py:93\u001b[0m, in \u001b[0;36mGroupBy.aggregate\u001b[0;34m(self, arg, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_translate_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:1927\u001b[0m, in \u001b[0;36mGroupBy.aggregate\u001b[0;34m(self, arg, split_every, split_out, shuffle_method, **kwargs)\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m-> 1927\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGroupbyAggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1942\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py:4799\u001b[0m, in \u001b[0;36mnew_collection\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_collection\u001b[39m(expr):\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4799\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   4800\u001b[0m     expr\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_collection_type(meta)(expr)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:436\u001b[0m, in \u001b[0;36mGroupbyAggregation._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_reductions.py:439\u001b[0m, in \u001b[0;36mApplyConcatApply._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 439\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta_chunk\u001b[49m\n\u001b[1;32m    440\u001b[0m     aggregate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x: x)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:210\u001b[0m, in \u001b[0;36mGroupByApplyConcatApply._meta_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    209\u001b[0m     meta \u001b[38;5;241m=\u001b[39m meta_nonempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39m_meta)\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk(meta, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_meta, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_kwargs\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:527\u001b[0m, in \u001b[0;36mDecomposableGroupbyAggregation.chunk_kwargs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_kwargs\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuncs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_args\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msort\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort,\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_as_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved),\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_as_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropna\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna),\n\u001b[1;32m    531\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_groupby.py:408\u001b[0m, in \u001b[0;36mGroupbyAggregationBase.agg_args\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_args\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    407\u001b[0m     keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinalizers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, \u001b[43m_build_agg_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/groupby.py:891\u001b[0m, in \u001b[0;36m_build_agg_args\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, Aggregation):\n\u001b[1;32m    889\u001b[0m     func \u001b[38;5;241m=\u001b[39m funcname(known_np_funcs\u001b[38;5;241m.\u001b[39mget(func, func))\n\u001b[0;32m--> 891\u001b[0m impls \u001b[38;5;241m=\u001b[39m \u001b[43m_build_agg_args_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_column\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# overwrite existing result-columns, generate intermediates only once\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m impls[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/groupby.py:950\u001b[0m, in \u001b[0;36m_build_agg_args_single\u001b[0;34m(result_column, func, func_args, func_kwargs, input_column)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _build_agg_args_custom(result_column, func, input_column)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown aggregate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: unknown aggregate lambda"
     ]
    }
   ],
   "source": [
    "# cc_grouped = cc_result.groupby('group').agg({'doc_id': 'count'}).rename(columns={'doc_id': 'count'}).sort_values('count', ascending=False).compute()\n",
    "\n",
    "cc_grouped = cc_result.groupby('group').agg({\n",
    "    'id': lambda x: x.str.split('-').str[0].nunique()\n",
    "}).rename(columns={'id': 'count'}).sort_values('count', ascending=False).compute()\n",
    "cc_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def7323-3d2c-4861-9b7e-a1e296ccf329",
   "metadata": {},
   "source": [
    "[Optional] Verify if fuzzy duplicates are similar. For example, we can look into the largest group \"350652173\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22cb491-c2ab-4ec4-8313-ae2bcd66a352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350652173</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1285625132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350652173</th>\n",
       "      <td>256213913</td>\n",
       "      <td>2033200488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350652173</th>\n",
       "      <td>256213913</td>\n",
       "      <td>428016172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350652173</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1268721963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350652173</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1285428574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset_id      doc_id\n",
       "group                            \n",
       "350652173   256213913  1285625132\n",
       "350652173   256213913  2033200488\n",
       "350652173   256213913   428016172\n",
       "350652173   256213913  1268721963\n",
       "350652173   256213913  1285428574"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_group = cc_result.loc[350652173].compute()\n",
    "dup_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c1cf4-8cb9-4f10-aab3-acfdaa9e5b16",
   "metadata": {},
   "source": [
    "We will examine the first five documents in this cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cf923e-fd4e-41b9-a00f-801c186ac70e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 37848 files\n"
     ]
    }
   ],
   "source": [
    "# read input dataset\n",
    "input_data_dir = os.path.join(base_dir, \"rpv2-2023-06-en-cleaned\")\n",
    "input_dataset = DocumentDataset.read_json(input_data_dir, add_filename=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772bf71-9e18-4e59-b9f8-ebd9053c79b0",
   "metadata": {},
   "source": [
    "Let's visualize the content of these documents and see if they are similar (ids may change so revise the `dup_ids` as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cc167f-30f8-470d-99e3-0a2d916d46bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for near duplicate examples with specific IDs took 610.5046670436859 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "dup_ids = [\n",
    "    'rpv2-2023-06-1285625132',\n",
    "    'rpv2-2023-06-2033200488',\n",
    "    'rpv2-2023-06-0428016172',\n",
    "    'rpv2-2023-06-1268721963',\n",
    "    'rpv2-2023-06-1285428574'\n",
    "] \n",
    "dup_examples = input_dataset.df[input_dataset.df['id'].isin(dup_ids)].compute()\n",
    "print(f\"Searching for near duplicate examples with specific IDs took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a4b3e-8a48-441c-8e12-9b2d287b79ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1b00a-501e-4d49-a93b-60a5c8ae87d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Example duplicate 1\\n' + dup_examples.raw_content.iloc[0])\n",
    "print('\\n\\nExample duplicate 2\\n' + dup_examples.raw_content.iloc[1])\n",
    "print('\\n\\nExample duplicate 3\\n' + dup_examples.raw_content.iloc[2])\n",
    "print('\\n\\nExample duplicate 4\\n' + dup_examples.raw_content.iloc[3])\n",
    "print('\\n\\nExample duplicate 4\\n' + dup_examples.raw_content.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428e09c-5442-4908-8888-4e62994e4c5c",
   "metadata": {},
   "source": [
    "### 5.2.7 Duplicates Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e01b84-07cc-45a3-9dde-97884d1922a3",
   "metadata": {},
   "source": [
    "Next, we will proceed to remove the duplicates identified from the dataset. We will first change the string ID to `doc_id` and `dataset_id` in the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cde97c5-cfaa-4096-8d9f-1ffa19c4adb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1792 files\n"
     ]
    }
   ],
   "source": [
    "from helper import convert_str_id_to_int\n",
    "\n",
    "input_dataset = DocumentDataset.read_json(os.path.join(base_dir, \"../clean_c4_en_cleaned\"))\n",
    "input_df = input_dataset.df[['text','id']]\n",
    "meta = input_df._meta\n",
    "meta['doc_id']=np.int64([0])\n",
    "meta['dataset_id']=np.uint32([0])\n",
    "input_df = input_df.map_partitions(\n",
    "    convert_str_id_to_int,\n",
    "    id_column=\"id\",\n",
    "    meta=meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e50a79-18b0-4d1b-bab0-cfd1ec9b62fd",
   "metadata": {},
   "source": [
    "Then, we will perform a merge between the `input_df` and the `docs_to_remove` on the IDs and drop the fuzzy duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f880a6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "2024-11-06 12:09:04,876 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837', 998)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((<function Fused._execute_task at 0x7ff381b4bd90>, {'read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837': ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 998), ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 998): (<function apply at 0x7ff3fb540160>, <function apply_and_enforce at 0x7ff38237fbe0>, [('getitem-c07894a7fd914c16d3773a255c06073f', 998)], {'id_column': 'id', '_func': <function convert_str_id_to_int at 0x7ff2f0f13b50>, '_meta': Empty DataFrame\n",
      "Columns: [text, id, doc_id, dataset_id]\n",
      "Index: []}), ('getitem-c07894a7fd914c16d3773a255c06073f', 998): (<built-in function getitem>, ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 998), ['text', 'id']), ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 998): (<function apply at 0x7ff3fb540160>, <function read_single_partition at 0x7ff2d0337e20>, [['/home/neelesh/4_new_c4/../clean_c4_en_cleaned/c4-train00998.jsonl']], {'filetype': 'jsonl', 'backend': 'pandas',\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Series\\' object has no attribute \\'hash_values\\'\")'\n",
      "Traceback: '  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 3765, in _execute_task\\n    return dask.core.get(graph, name)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 163, in get\\n    result = _execute_task(task, cache)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 133, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/utils.py\", line 78, in apply\\n    return func(*args, **kwargs)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/core.py\", line 7175, in apply_and_enforce\\n    df = func(*args, **kwargs)\\n  File \"/home/neelesh/NEMO_DATA/helper.py\", line 53, in convert_str_id_to_int\\n    df[\"dataset_id\"] = dx[0].hash_values()\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n'\n",
      "\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'hash_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2078536/2319690685.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Create output directory and process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdedup_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_outdir_and_mkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../clean_c4_deduped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Process the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_str_id_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Remove duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDaskMethodsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mshorten_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NEMO_DATA/helper.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'hash_values'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    }
   ],
   "source": [
    "def convert_str_id_to_int(df, id_column='id'):\n",
    "    # Make a deep copy of the dataframe\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    # Split the id column\n",
    "    dx = df[id_column].str.split('-', expand=True)\n",
    "    \n",
    "    # Use loc for safe assignment\n",
    "    df.loc[:, 'doc_id'] = dx[1].astype('int64')\n",
    "    \n",
    "    # Hash computation\n",
    "    import hashlib\n",
    "    df.loc[:, 'dataset_id'] = dx[0].apply(lambda x: int(hashlib.md5(str(x).encode()).hexdigest()[:8], 16))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create output directory and process\n",
    "dedup_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"../clean_c4_deduped\"))\n",
    "\n",
    "# Process the data\n",
    "input_df = input_df.compute()\n",
    "input_df = convert_str_id_to_int(input_df)\n",
    "\n",
    "# Remove duplicates\n",
    "deduped_df = input_df[~input_df['id'].isin(docs_to_remove['to_remove_id'])]\n",
    "\n",
    "# Write to parquet\n",
    "t0 = time.time()\n",
    "deduped_df.to_parquet(dedup_output_dir)\n",
    "print(f\"Removing duplicates and writing deduped dataset took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ae4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "2024-11-06 12:07:16,198 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837', 996)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((<function Fused._execute_task at 0x7fc886f4fd90>, {'read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837': ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 996), ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 996): (<function apply at 0x7fc900b74160>, <function apply_and_enforce at 0x7fc887783be0>, [('getitem-c07894a7fd914c16d3773a255c06073f', 996)], {'id_column': 'id', '_func': <function convert_str_id_to_int at 0x7fc7bc16ca60>, '_meta': Empty DataFrame\n",
      "Columns: [text, id, doc_id, dataset_id]\n",
      "Index: []}), ('getitem-c07894a7fd914c16d3773a255c06073f', 996): (<built-in function getitem>, ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 996), ['text', 'id']), ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 996): (<function apply at 0x7fc900b74160>, <function read_single_partition at 0x7fc7bc16f9a0>, [['/home/neelesh/4_new_c4/../clean_c4_en_cleaned/c4-train00996.jsonl']], {'filetype': 'jsonl', 'backend': 'pandas',\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Series\\' object has no attribute \\'hash_values\\'\")'\n",
      "Traceback: '  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 3765, in _execute_task\\n    return dask.core.get(graph, name)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 163, in get\\n    result = _execute_task(task, cache)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 133, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/utils.py\", line 78, in apply\\n    return func(*args, **kwargs)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/core.py\", line 7175, in apply_and_enforce\\n    df = func(*args, **kwargs)\\n  File \"/home/neelesh/NEMO_DATA/helper.py\", line 53, in convert_str_id_to_int\\n    df[\"dataset_id\"] = dx[0].hash_values()\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n'\n",
      "\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "2024-11-06 12:07:16,217 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837', 998)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((<function Fused._execute_task at 0x7f9ae8147d90>, {'read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837': ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 998), ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 998): (<function apply at 0x7f9b61d54160>, <function apply_and_enforce at 0x7f9ae8973be0>, [('getitem-c07894a7fd914c16d3773a255c06073f', 998)], {'id_column': 'id', '_func': <function convert_str_id_to_int at 0x7f9a55ddac20>, '_meta': Empty DataFrame\n",
      "Columns: [text, id, doc_id, dataset_id]\n",
      "Index: []}), ('getitem-c07894a7fd914c16d3773a255c06073f', 998): (<built-in function getitem>, ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 998), ['text', 'id']), ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 998): (<function apply at 0x7f9b61d54160>, <function read_single_partition at 0x7f998584e950>, [['/home/neelesh/4_new_c4/../clean_c4_en_cleaned/c4-train00998.jsonl']], {'filetype': 'jsonl', 'backend': 'pandas',\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Series\\' object has no attribute \\'hash_values\\'\")'\n",
      "Traceback: '  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 3765, in _execute_task\\n    return dask.core.get(graph, name)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 163, in get\\n    result = _execute_task(task, cache)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 133, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/utils.py\", line 78, in apply\\n    return func(*args, **kwargs)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/core.py\", line 7175, in apply_and_enforce\\n    df = func(*args, **kwargs)\\n  File \"/home/neelesh/NEMO_DATA/helper.py\", line 53, in convert_str_id_to_int\\n    df[\"dataset_id\"] = dx[0].hash_values()\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n'\n",
      "\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "2024-11-06 12:07:16,243 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837', 997)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((<function Fused._execute_task at 0x7ff381b4bd90>, {'read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837': ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 997), ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 997): (<function apply at 0x7ff3fb540160>, <function apply_and_enforce at 0x7ff38237fbe0>, [('getitem-c07894a7fd914c16d3773a255c06073f', 997)], {'id_column': 'id', '_func': <function convert_str_id_to_int at 0x7ff2f0f13b50>, '_meta': Empty DataFrame\n",
      "Columns: [text, id, doc_id, dataset_id]\n",
      "Index: []}), ('getitem-c07894a7fd914c16d3773a255c06073f', 997): (<built-in function getitem>, ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 997), ['text', 'id']), ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 997): (<function apply at 0x7ff3fb540160>, <function read_single_partition at 0x7ff2d0337e20>, [['/home/neelesh/4_new_c4/../clean_c4_en_cleaned/c4-train00997.jsonl']], {'filetype': 'jsonl', 'backend': 'pandas',\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Series\\' object has no attribute \\'hash_values\\'\")'\n",
      "Traceback: '  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 3765, in _execute_task\\n    return dask.core.get(graph, name)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 163, in get\\n    result = _execute_task(task, cache)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 133, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/utils.py\", line 78, in apply\\n    return func(*args, **kwargs)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/core.py\", line 7175, in apply_and_enforce\\n    df = func(*args, **kwargs)\\n  File \"/home/neelesh/NEMO_DATA/helper.py\", line 53, in convert_str_id_to_int\\n    df[\"dataset_id\"] = dx[0].hash_values()\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n'\n",
      "\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'hash_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2078536/2932026644.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdedup_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_outdir_and_mkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../clean_c4_deduped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Filter out rows where id is in the to_remove_id list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeduped_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_to_remove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'to_remove_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDaskMethodsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mshorten_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NEMO_DATA/helper.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'hash_values'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dedup_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"../clean_c4_deduped\"))\n",
    "input_df = input_df.compute()\n",
    "\n",
    "# Filter out rows where id is in the to_remove_id list\n",
    "deduped_df = input_df[~input_df['id'].isin(docs_to_remove['to_remove_id'])]\n",
    "\n",
    "t0 = time.time()\n",
    "deduped_df.to_parquet(dedup_output_dir)\n",
    "print(f\"Removing duplicates and writing deduped dataset took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819d1d3-c4c0-4288-b190-86276d221050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "2024-11-06 12:04:47,343 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837', 996)\n",
      "State:     executing\n",
      "Function:  execute_task\n",
      "args:      ((<function Fused._execute_task at 0x7ff08fb4bd90>, {'read_single_partition-getitem-convert_str_id_to_int-fa420657f4c775fc4951a135b3a23837': ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 996), ('convert_str_id_to_int-d81d02f032afe14e77a472319de3a460', 996): (<function apply at 0x7ff1096e0160>, <function apply_and_enforce at 0x7ff09037fbe0>, [('getitem-c07894a7fd914c16d3773a255c06073f', 996)], {'id_column': 'id', '_func': <function convert_str_id_to_int at 0x7fefe8120f70>, '_meta': Empty DataFrame\n",
      "Columns: [text, id, doc_id, dataset_id]\n",
      "Index: []}), ('getitem-c07894a7fd914c16d3773a255c06073f', 996): (<built-in function getitem>, ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 996), ['text', 'id']), ('read_single_partition-a03a5c1db4b90694c3746a2eecea30f8', 996): (<function apply at 0x7ff1096e0160>, <function read_single_partition at 0x7fefe81c0ee0>, [['/home/neelesh/4_new_c4/../clean_c4_en_cleaned/c4-train00996.jsonl']], {'filetype': 'jsonl', 'backend': 'pandas',\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Series\\' object has no attribute \\'hash_values\\'\")'\n",
      "Traceback: '  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\", line 3765, in _execute_task\\n    return dask.core.get(graph, name)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 163, in get\\n    result = _execute_task(task, cache)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/core.py\", line 133, in _execute_task\\n    return func(*(_execute_task(a, cache) for a in args))\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/utils.py\", line 78, in apply\\n    return func(*args, **kwargs)\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/core.py\", line 7175, in apply_and_enforce\\n    df = func(*args, **kwargs)\\n  File \"/home/neelesh/NEMO_DATA/helper.py\", line 53, in convert_str_id_to_int\\n    df[\"dataset_id\"] = dx[0].hash_values()\\n  File \"/home/neelesh/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n'\n",
      "\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'hash_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2078536/3784073552.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Now for the deduplication process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdedup_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_outdir_and_mkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../clean_c4_deduped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Compute the Dask DataFrame to pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Perform the merge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m deduped_df = input_df.merge(\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDaskMethodsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mshorten_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_expr.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NEMO_DATA/helper.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'hash_values'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n",
      "/home/neelesh/NEMO_DATA/helper.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"doc_id\"] = dx[1].astype(\"int64\").values\n"
     ]
    }
   ],
   "source": [
    "dedup_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"../clean_c4_deduped\"))\n",
    "input_df = input_df.compute()\n",
    "deduped_df = input_df.merge(docs_to_remove,\n",
    "                             left_on=['id'],\n",
    "                             right_on=[\"to_remove_id\"],\n",
    "                             how='left')\n",
    "\n",
    "deduped_df = deduped_df[deduped_df['to_remove_id'].isna()].drop(columns=['to_remove_id']).reset_index(drop=True)\n",
    "\n",
    "t0 = time.time()\n",
    "deduped_df.to_parquet(dedup_output_dir)\n",
    "print(f\"Removing duplicates and writing deduped dataset took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987b1ac-c8e3-45f8-8e9b-32befc6667aa",
   "metadata": {},
   "source": [
    "To verify the results, we can confirm that we have 849,273,787 documents left compared to 1,088,311,520 in the input dataset, essentially removing 239,037,733 duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf56c9ca-27cb-4f03-921b-685d523cf43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849273787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deduped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f96f15-1ac6-40ab-9e04-1586531bb55f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088311520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6350e-2363-4b13-ac67-0cbc23ad981d",
   "metadata": {},
   "source": [
    "## 5.3 Inter-snapshot Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2b15-961f-4a73-a0a3-15474ae4134c",
   "metadata": {},
   "source": [
    "So far we have deduplicated a single snapshot from rpv2. Pre-training dataet include multiple snapshots so we will often need to perform inter-snapshot deduplication. For this tutorial, we will demostrate deduplication across two snapshots as an example.\n",
    "\n",
    "We first performed all the above steps for another snapshot `2023-14` and then combined the two deduped datasets into one and stored them in `rpv2-2023-06-and-14-deduped`.\n",
    "\n",
    "Next, we will perform the fuzzy deduplication on the combined dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1445cc-b69c-4007-8f09-75a8eb8f699c",
   "metadata": {},
   "source": [
    "### 5.3.1 Compute Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1461b61-887c-4099-bd9f-32e79dc5fdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemo_curator import MinHash\n",
    "from nemo_curator import LSH\n",
    "from nemo_curator.modules.fuzzy_dedup import _MapBuckets\n",
    "from nemo_curator.modules.fuzzy_dedup import _Shuffle\n",
    "from nemo_curator.modules.fuzzy_dedup import ConnectedComponents\n",
    "from nemo_curator.modules.fuzzy_dedup import JaccardSimilarity\n",
    "\n",
    "from nemo_curator.utils.file_utils import reshard_jsonl\n",
    "from nemo_curator.utils.fuzzy_dedup_utils.id_mapping import convert_str_id_to_int\n",
    "from nemo_curator.utils.fuzzy_dedup_utils.io_utils import (\n",
    "    get_bucket_ddf_from_parquet_path,\n",
    "    get_text_ddf_from_json_path_with_blocksize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efaed1ed-e6d1-4117-9b0b-fe0d20960b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "minhash_length = 260\n",
    "char_ngram = 5\n",
    "log_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"logs\"))\n",
    "id_field = 'id'\n",
    "text_field = 'raw_content'\n",
    "minshah_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"rpv2-2023-06-and-14-minhash\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bf2d09-6601-4bd2-a6f2-f738cffd8885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data_dir = os.path.join(base_dir,\"rpv2-2023-06-and-14-deduped\")\n",
    "\n",
    "files = []\n",
    "for file in os.listdir(input_data_dir):\n",
    "    if file.endswith('.part'):\n",
    "        new_file = file.replace('.part', '.jsonl')\n",
    "        old_file_path = os.path.join(input_data_dir, file)\n",
    "        new_file_path = os.path.join(input_data_dir, new_file)\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "    files.append(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38197174-738e-42a4-a38a-1dbd7d84836d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 72797 files\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in files if f.endswith(\".jsonl\")]\n",
    "df = read_data(\n",
    "    files,\n",
    "    file_type=\"jsonl\",\n",
    "    backend=\"cudf\",\n",
    "    files_per_partition=2,\n",
    "    add_filename=False,\n",
    ")[[id_field, text_field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "439add9c-9f51-4481-95cf-456dc5be9fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing minhashes took:6115.702769517899\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run MinHash() on input data\n",
    "minhasher = MinHash(\n",
    "    seed=seed,\n",
    "    num_hashes=minhash_length,\n",
    "    char_ngrams=char_ngram,\n",
    "    use_64bit_hash=False,\n",
    "    logger=log_dir,\n",
    "    id_field=id_field,\n",
    "    text_field=text_field,\n",
    "    cache_dir=minshah_output_dir\n",
    ")\n",
    "\n",
    "result = minhasher(DocumentDataset(df)).df\n",
    "\n",
    "print(f\"Computing minhashes took:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c998d64-54f8-49b0-8e0c-2e5727596e84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_minhash_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rpv2-2023-06-0678400000</td>\n",
       "      <td>[36422228, 15993596, 3538361, 16103012, 194100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rpv2-2023-06-0678500000</td>\n",
       "      <td>[34662, 17635, 1112347, 293654, 313382, 160184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rpv2-2023-06-0678600000</td>\n",
       "      <td>[15076006, 1801689, 3181854, 2949398, 5699436,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rpv2-2023-06-0678700000</td>\n",
       "      <td>[13528976, 2438382, 26260517, 26187347, 249748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rpv2-2023-06-0678800000</td>\n",
       "      <td>[2550974, 157261, 1536526, 1169030, 576861, 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                 _minhash_signature\n",
       "0  rpv2-2023-06-0678400000  [36422228, 15993596, 3538361, 16103012, 194100...\n",
       "1  rpv2-2023-06-0678500000  [34662, 17635, 1112347, 293654, 313382, 160184...\n",
       "2  rpv2-2023-06-0678600000  [15076006, 1801689, 3181854, 2949398, 5699436,...\n",
       "3  rpv2-2023-06-0678700000  [13528976, 2438382, 26260517, 26187347, 249748...\n",
       "4  rpv2-2023-06-0678800000  [2550974, 157261, 1536526, 1169030, 576861, 10..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3af9e-9e03-4950-93c0-92792f9ad24b",
   "metadata": {},
   "source": [
    "### 5.3.2 Minhash LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11c2f37-3b78-4e1b-a9ff-4a89b38f3604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lsh_input_dir = os.path.join(base_dir,\"rpv2-2023-06-and-14-minhash\")\n",
    "id_field = 'id'\n",
    "output_bucket_dir = expand_outdir_and_mkdir(os.path.join(base_dir,\"fuzzy-dedup-output-2023-06-and-14\"))\n",
    "num_bands = 20\n",
    "buckets_per_shuffle = 1\n",
    "minhash_field = '_minhash_signature'\n",
    "minhash_length = 260\n",
    "log_dir = os.path.join(base_dir, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a243ed7a-9175-488f-8097-5b82c47c5708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSH took 10536.635195493698 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#Load MinHash output\n",
    "df = dask_cudf.read_parquet(lsh_input_dir, blocksize=\"2GB\", aggregate_files=True)\n",
    "df = df.map_partitions(\n",
    "    convert_str_id_to_int,\n",
    "    id_column=id_field,\n",
    "    meta=cudf.DataFrame(\n",
    "        {minhash_field: [[1, 2, 3]], \"doc_id\": [1], \"dataset_id\": np.uint32(1)}\n",
    "    ),\n",
    ")\n",
    "\n",
    "lsh = LSH(\n",
    "    cache_dir=output_bucket_dir,\n",
    "    num_hashes=minhash_length,\n",
    "    num_buckets=num_bands,\n",
    "    buckets_per_shuffle=buckets_per_shuffle,\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"],\n",
    "    minhash_field=minhash_field,\n",
    "    logger=log_dir,\n",
    ")\n",
    "\n",
    "lsh_result = lsh(DocumentDataset(df))\n",
    "print(f\"LSH took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea85033-e275-4b62-8351-6c85ac5ac83b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>_bucket_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256213913</td>\n",
       "      <td>2480637085</td>\n",
       "      <td>74400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256213913</td>\n",
       "      <td>2079208983</td>\n",
       "      <td>88082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1142812586</td>\n",
       "      <td>7198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4217914658</td>\n",
       "      <td>3589401712</td>\n",
       "      <td>54808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1827931650</td>\n",
       "      <td>58134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id      doc_id  _bucket_id\n",
       "0   256213913  2480637085       74400\n",
       "1   256213913  2079208983       88082\n",
       "2   256213913  1142812586        7198\n",
       "3  4217914658  3589401712       54808\n",
       "4   256213913  1827931650       58134"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_result.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c79b8-229f-47ee-9e01-a7bf1f317250",
   "metadata": {},
   "source": [
    "### 5.3.3 Map Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc909e1-e02e-433d-b6c2-e7f82a137438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data_paths = [os.path.join(base_dir,\"rpv2-2023-06-and-14-deduped\")]\n",
    "num_files = None\n",
    "text_ddf_blocksize = 256 #The block size for chunking jsonl files for text ddf in mb\n",
    "id_field = 'id'\n",
    "text_field = 'raw_content'\n",
    "input_bucket_path = os.path.join(base_dir,\"fuzzy-dedup-output-2023-06-and-14/_buckets.parquet\")\n",
    "input_bucket_field = '_bucket_id'\n",
    "shuffle_type ='tasks'\n",
    "log_dir = os.path.join(base_dir, \"logs\")\n",
    "output_anchor_docs_with_bk_path = expand_outdir_and_mkdir(os.path.join(base_dir,\"fuzzy-dedup-output-2023-06-and-14/anchor_docs_with_bk.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3effff2a-f01d-4f33-b495-97455a280a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files being read for jaccard calculation = 72797\n",
      "ddf_text.npartitions  = 23876\n"
     ]
    }
   ],
   "source": [
    "# Read .jsonl input data\n",
    "ddf_text = get_text_ddf_from_json_path_with_blocksize(\n",
    "    input_data_paths=input_data_paths,\n",
    "    num_files=num_files,\n",
    "    blocksize=text_ddf_blocksize,\n",
    "    id_column=id_field,\n",
    "    text_column=text_field,\n",
    ")\n",
    "\n",
    "print(f\"ddf_text.npartitions  = {ddf_text.npartitions}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e00d8e-170c-4adf-bf34-1ad1b5275760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ddf_bk partitions = 54\n",
      "Mapping Bucket took 1034.9348919391632 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "num_workers = get_num_workers(gpu_client)\n",
    "\n",
    "# Read \"_buckets.parquet\"\n",
    "ddf_bk = get_bucket_ddf_from_parquet_path(\n",
    "    input_bucket_path=input_bucket_path, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "#Run _MapBuckets()\n",
    "map_buckets = _MapBuckets(\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"], \n",
    "    bucket_field=input_bucket_field, \n",
    "    logger=log_dir,\n",
    "    text_field=text_field,\n",
    ")\n",
    "\n",
    "ddf_anchor_docs_with_bk = map_buckets.map_buckets_with_anchors(\n",
    "    documents_df=ddf_text, \n",
    "    buckets_df=ddf_bk, \n",
    "    shuffle_type=shuffle_type\n",
    ")\n",
    "\n",
    "#Write to disk\n",
    "ddf_anchor_docs_with_bk.to_parquet(\n",
    "    output_anchor_docs_with_bk_path, \n",
    "    write_index=False\n",
    ")\n",
    "\n",
    "print(f\"Mapping Bucket took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0718d8e-5143-458f-ab59-a440adcde8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>anchor_1_dataset_id</th>\n",
       "      <th>anchor_1_doc_id</th>\n",
       "      <th>anchor_0_dataset_id</th>\n",
       "      <th>anchor_0_doc_id</th>\n",
       "      <th>_output_partition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4217914658</td>\n",
       "      <td>518211850</td>\n",
       "      <td>4217914658</td>\n",
       "      <td>518211850</td>\n",
       "      <td>256213913</td>\n",
       "      <td>491920892</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4217914658</td>\n",
       "      <td>6364303356</td>\n",
       "      <td>256213913</td>\n",
       "      <td>2308804621</td>\n",
       "      <td>4217914658</td>\n",
       "      <td>6364303356</td>\n",
       "      <td>4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256213913</td>\n",
       "      <td>2103535708</td>\n",
       "      <td>4217914658</td>\n",
       "      <td>1208111155</td>\n",
       "      <td>256213913</td>\n",
       "      <td>2103535708</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256213913</td>\n",
       "      <td>1359208912</td>\n",
       "      <td>4217914658</td>\n",
       "      <td>6342510538</td>\n",
       "      <td>256213913</td>\n",
       "      <td>1359208912</td>\n",
       "      <td>3738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256213913</td>\n",
       "      <td>162316349</td>\n",
       "      <td>256213913</td>\n",
       "      <td>162316349</td>\n",
       "      <td>4217914658</td>\n",
       "      <td>1033014280</td>\n",
       "      <td>4258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id      doc_id  anchor_1_dataset_id  anchor_1_doc_id  \\\n",
       "0  4217914658   518211850           4217914658        518211850   \n",
       "1  4217914658  6364303356            256213913       2308804621   \n",
       "2   256213913  2103535708           4217914658       1208111155   \n",
       "3   256213913  1359208912           4217914658       6342510538   \n",
       "4   256213913   162316349            256213913        162316349   \n",
       "\n",
       "   anchor_0_dataset_id  anchor_0_doc_id  _output_partition_id  \n",
       "0            256213913        491920892                  2004  \n",
       "1           4217914658       6364303356                  4246  \n",
       "2            256213913       2103535708                  4003  \n",
       "3            256213913       1359208912                  3738  \n",
       "4           4217914658       1033014280                  4258  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_anchor_docs_with_bk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca84869-9991-429c-baa1-bccadd15cafa",
   "metadata": {},
   "source": [
    "### 6.8.4 Jaccard Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbce892-ec9c-46e3-9fbe-09f9a243a7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(base_dir, \"logs\")\n",
    "input_anchor_docs_with_bk_path = os.path.join(base_dir,\"fuzzy-dedup-output-2023-06-and-14/anchor_docs_with_bk.parquet\")\n",
    "output_shuffled_docs_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/shuffled_docs.parquet\")\n",
    ")\n",
    "bucket_mapping_ddf_blocksize = 256\n",
    "parts_per_worker = 16\n",
    "bucket_parts_per_worker = 256\n",
    "id_field = 'id'\n",
    "text_field = 'raw_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acd3e4a-0310-4413-98b2-07cd7c74ee57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started processing bucket-map partitions 0 through 54 of 54\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4620819 rows to disk\n",
      "Text-df partition  256/23876 completed in 105.13463497161865\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4520986 rows to disk\n",
      "Text-df partition  512/23876 completed in 100.3475558757782\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5232824 rows to disk\n",
      "Text-df partition  768/23876 completed in 56.71416783332825\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4700161 rows to disk\n",
      "Text-df partition  1024/23876 completed in 27.45123529434204\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4638892 rows to disk\n",
      "Text-df partition  1280/23876 completed in 26.144277334213257\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4973176 rows to disk\n",
      "Text-df partition  1536/23876 completed in 28.32722544670105\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4739295 rows to disk\n",
      "Text-df partition  1792/23876 completed in 27.41572093963623\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4666429 rows to disk\n",
      "Text-df partition  2048/23876 completed in 28.092216730117798\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4575038 rows to disk\n",
      "Text-df partition  2304/23876 completed in 28.87087869644165\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4614105 rows to disk\n",
      "Text-df partition  2560/23876 completed in 29.3941969871521\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4971503 rows to disk\n",
      "Text-df partition  2816/23876 completed in 52.00490689277649\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4848209 rows to disk\n",
      "Text-df partition  3072/23876 completed in 71.0807855129242\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4611715 rows to disk\n",
      "Text-df partition  3328/23876 completed in 29.228161811828613\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4588284 rows to disk\n",
      "Text-df partition  3584/23876 completed in 28.400054931640625\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5171055 rows to disk\n",
      "Text-df partition  3840/23876 completed in 26.41180109977722\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5327078 rows to disk\n",
      "Text-df partition  4096/23876 completed in 26.196251392364502\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4916667 rows to disk\n",
      "Text-df partition  4352/23876 completed in 27.100730657577515\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5001533 rows to disk\n",
      "Text-df partition  4608/23876 completed in 27.554187536239624\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4582622 rows to disk\n",
      "Text-df partition  4864/23876 completed in 29.70548677444458\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4605499 rows to disk\n",
      "Text-df partition  5120/23876 completed in 27.098711490631104\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4684486 rows to disk\n",
      "Text-df partition  5376/23876 completed in 25.721199989318848\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4906546 rows to disk\n",
      "Text-df partition  5632/23876 completed in 27.30464768409729\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4970474 rows to disk\n",
      "Text-df partition  5888/23876 completed in 26.972269535064697\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4809087 rows to disk\n",
      "Text-df partition  6144/23876 completed in 26.392934322357178\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4601077 rows to disk\n",
      "Text-df partition  6400/23876 completed in 27.80239224433899\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4717842 rows to disk\n",
      "Text-df partition  6656/23876 completed in 25.849796295166016\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4635998 rows to disk\n",
      "Text-df partition  6912/23876 completed in 25.058417797088623\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4717614 rows to disk\n",
      "Text-df partition  7168/23876 completed in 26.111382961273193\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4668000 rows to disk\n",
      "Text-df partition  7424/23876 completed in 26.136395692825317\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4696823 rows to disk\n",
      "Text-df partition  7680/23876 completed in 25.99736261367798\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4733828 rows to disk\n",
      "Text-df partition  7936/23876 completed in 26.545007944107056\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4979121 rows to disk\n",
      "Text-df partition  8192/23876 completed in 32.05287790298462\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4939324 rows to disk\n",
      "Text-df partition  8448/23876 completed in 28.708505868911743\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5042342 rows to disk\n",
      "Text-df partition  8704/23876 completed in 26.08993935585022\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4844436 rows to disk\n",
      "Text-df partition  8960/23876 completed in 27.56988835334778\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4825293 rows to disk\n",
      "Text-df partition  9216/23876 completed in 37.68942975997925\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4905616 rows to disk\n",
      "Text-df partition  9472/23876 completed in 42.70246362686157\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4779850 rows to disk\n",
      "Text-df partition  9728/23876 completed in 26.989847660064697\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4710747 rows to disk\n",
      "Text-df partition  9984/23876 completed in 25.826035737991333\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4597185 rows to disk\n",
      "Text-df partition  10240/23876 completed in 34.76953339576721\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4587079 rows to disk\n",
      "Text-df partition  10496/23876 completed in 27.512352228164673\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5238085 rows to disk\n",
      "Text-df partition  10752/23876 completed in 31.53863787651062\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4857048 rows to disk\n",
      "Text-df partition  11008/23876 completed in 31.474143266677856\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4626954 rows to disk\n",
      "Text-df partition  11264/23876 completed in 25.94492197036743\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4566911 rows to disk\n",
      "Text-df partition  11520/23876 completed in 28.600372552871704\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4642402 rows to disk\n",
      "Text-df partition  11776/23876 completed in 29.29861807823181\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4620988 rows to disk\n",
      "Text-df partition  12032/23876 completed in 54.01084804534912\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4852834 rows to disk\n",
      "Text-df partition  12288/23876 completed in 31.626899003982544\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5003031 rows to disk\n",
      "Text-df partition  12544/23876 completed in 28.87297010421753\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4971127 rows to disk\n",
      "Text-df partition  12800/23876 completed in 26.830497980117798\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5021170 rows to disk\n",
      "Text-df partition  13056/23876 completed in 30.301889419555664\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4905513 rows to disk\n",
      "Text-df partition  13312/23876 completed in 30.292287349700928\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4995374 rows to disk\n",
      "Text-df partition  13568/23876 completed in 29.753846168518066\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4906740 rows to disk\n",
      "Text-df partition  13824/23876 completed in 32.25304961204529\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4926631 rows to disk\n",
      "Text-df partition  14080/23876 completed in 30.16843581199646\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4945429 rows to disk\n",
      "Text-df partition  14336/23876 completed in 38.25400948524475\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5012098 rows to disk\n",
      "Text-df partition  14592/23876 completed in 29.196772813796997\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4941308 rows to disk\n",
      "Text-df partition  14848/23876 completed in 26.616740465164185\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5008856 rows to disk\n",
      "Text-df partition  15104/23876 completed in 28.01602029800415\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5001177 rows to disk\n",
      "Text-df partition  15360/23876 completed in 26.971165895462036\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4889858 rows to disk\n",
      "Text-df partition  15616/23876 completed in 28.79030132293701\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4942402 rows to disk\n",
      "Text-df partition  15872/23876 completed in 27.89959168434143\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4851478 rows to disk\n",
      "Text-df partition  16128/23876 completed in 26.36684012413025\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4864522 rows to disk\n",
      "Text-df partition  16384/23876 completed in 30.089901208877563\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4864759 rows to disk\n",
      "Text-df partition  16640/23876 completed in 26.31510853767395\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4924232 rows to disk\n",
      "Text-df partition  16896/23876 completed in 29.793168544769287\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4847617 rows to disk\n",
      "Text-df partition  17152/23876 completed in 44.93840026855469\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4892815 rows to disk\n",
      "Text-df partition  17408/23876 completed in 29.60913062095642\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4874648 rows to disk\n",
      "Text-df partition  17664/23876 completed in 28.45934772491455\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4817302 rows to disk\n",
      "Text-df partition  17920/23876 completed in 52.390358448028564\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4847723 rows to disk\n",
      "Text-df partition  18176/23876 completed in 29.15921926498413\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4908017 rows to disk\n",
      "Text-df partition  18432/23876 completed in 27.583523750305176\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4868508 rows to disk\n",
      "Text-df partition  18688/23876 completed in 29.553890705108643\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4802031 rows to disk\n",
      "Text-df partition  18944/23876 completed in 25.65942096710205\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4893437 rows to disk\n",
      "Text-df partition  19200/23876 completed in 26.02946424484253\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4788126 rows to disk\n",
      "Text-df partition  19456/23876 completed in 26.086455821990967\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4785947 rows to disk\n",
      "Text-df partition  19712/23876 completed in 28.09809684753418\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4824750 rows to disk\n",
      "Text-df partition  19968/23876 completed in 28.4943585395813\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4820688 rows to disk\n",
      "Text-df partition  20224/23876 completed in 29.673362731933594\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4783326 rows to disk\n",
      "Text-df partition  20480/23876 completed in 51.86186718940735\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4813416 rows to disk\n",
      "Text-df partition  20736/23876 completed in 54.02740216255188\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4863187 rows to disk\n",
      "Text-df partition  20992/23876 completed in 22.822062015533447\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4788552 rows to disk\n",
      "Text-df partition  21248/23876 completed in 22.80601215362549\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4839959 rows to disk\n",
      "Text-df partition  21504/23876 completed in 22.84457564353943\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5041422 rows to disk\n",
      "Text-df partition  21760/23876 completed in 22.061447381973267\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5078608 rows to disk\n",
      "Text-df partition  22016/23876 completed in 23.05280375480652\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5001023 rows to disk\n",
      "Text-df partition  22272/23876 completed in 21.53549599647522\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5019361 rows to disk\n",
      "Text-df partition  22528/23876 completed in 22.766752243041992\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5024350 rows to disk\n",
      "Text-df partition  22784/23876 completed in 24.976530075073242\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5049981 rows to disk\n",
      "Text-df partition  23040/23876 completed in 24.01065444946289\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5032964 rows to disk\n",
      "Text-df partition  23296/23876 completed in 23.14147710800171\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 5020352 rows to disk\n",
      "Text-df partition  23552/23876 completed in 23.291804313659668\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 4978692 rows to disk\n",
      "Text-df partition  23808/23876 completed in 23.280447006225586\n",
      "Using 256 text partitions.\n",
      "Starting text bytes aware shuffle\n",
      "Will write 1372968 rows to disk\n",
      "Text-df partition  23876/23876 completed in 12.440344095230103\n",
      "Bucket partition  54/54 completed in 2962.5202176570892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [49:22<00:00, 2962.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Shuffle took 2963.7552287578583 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "shuffle = _Shuffle(\n",
    "    id_fields=[\"dataset_id\", \"doc_id\"],\n",
    "    text_field=text_field,\n",
    "    int_to_str_id=id_field,\n",
    "    logger=log_dir,\n",
    ")\n",
    "\n",
    "shuffle.shuffle_docs_on_buckets(\n",
    "    documents_df=ddf_text,\n",
    "    bucket_w_anchors_path=input_anchor_docs_with_bk_path,\n",
    "    output_shuffled_docs_path=output_shuffled_docs_path,\n",
    "    bucket_mapping_df_blocksize=bucket_mapping_ddf_blocksize,\n",
    "    parts_per_worker=parts_per_worker,\n",
    "    bucket_parts_per_worker=bucket_parts_per_worker,\n",
    "    partition_on=\"_output_partition_id\",\n",
    ")\n",
    "\n",
    "print(f\"Jaccard Shuffle took {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c70e6f-71dc-48c3-8759-439e6796ba27",
   "metadata": {},
   "source": [
    "### 5.3.5 Jaccard Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3890884-868e-473e-932d-02a17739b492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_field = 'id'\n",
    "text_field = 'raw_content'\n",
    "ngram_size = 5\n",
    "shuffled_docs_path = os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/shuffled_docs.parquet\")\n",
    "jaccard_results_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117cd113-c8f8-46a3-8173-231faff3b69d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Computing+Writing took 1300.0965530872345 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "jaccard = JaccardSimilarity(\n",
    "    id_field=id_field ,\n",
    "    text_field=text_field,\n",
    "    anchor_id_fields=[f\"anchor_{i}_{id_field}\" for i in range(2)],\n",
    "    ngram_width=ngram_size,\n",
    ")\n",
    "\n",
    "# Run actual computation\n",
    "result_df = jaccard.jaccard_compute(shuffled_docs_path)\n",
    "\n",
    "result_df.to_parquet(\n",
    "    jaccard_results_path,\n",
    "    write_index=False,\n",
    "    write_metadata_file=False,\n",
    ")\n",
    "\n",
    "print(f\"Jaccard Computing+Writing took {time.time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2307ab3-6d75-4e96-b2f3-dc180aed06ef",
   "metadata": {},
   "source": [
    "### 5.3.6 Connected Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd602c6e-39e5-45fe-9031-ea3926d68a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_dir = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/cc-cache\")\n",
    ")\n",
    "jaccard_pairs_path = os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet\")\n",
    "id_field = 'id'\n",
    "jaccard_threshold = 0.8\n",
    "output_path = expand_outdir_and_mkdir(\n",
    "    os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/connected_components.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89398db9-d4e6-48ec-bad8-1d5ac553cadd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_parquet method registered to the cudf backend.\nOriginal Message: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: /home/neelesh/4_new_c4/fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_collection.py:5467\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, dtype_backend, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, engine, arrow_to_pandas, **kwargs)\u001b[0m\n\u001b[1;32m   5448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[1;32m   5449\u001b[0m         ReadParquetPyarrowFS(\n\u001b[1;32m   5450\u001b[0m             path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5463\u001b[0m         )\n\u001b[1;32m   5464\u001b[0m     )\n\u001b[1;32m   5466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[0;32m-> 5467\u001b[0m     \u001b[43mReadParquetFSSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalculate_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_set_parquet_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5486\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/_core.py:57\u001b[0m, in \u001b[0;36mExpr.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m inst\u001b[38;5;241m.\u001b[39moperands \u001b[38;5;241m=\u001b[39m [_unpack_collections(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m operands]\n\u001b[0;32m---> 57\u001b[0m _name \u001b[38;5;241m=\u001b[39m \u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _name \u001b[38;5;129;01min\u001b[39;00m Expr\u001b[38;5;241m.\u001b[39m_instances:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/io/parquet.py:778\u001b[0m, in \u001b[0;36mReadParquet._name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_funcname\n\u001b[1;32m    776\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m         \u001b[38;5;241m+\u001b[39m _tokenize_deterministic(\n\u001b[0;32m--> 778\u001b[0m             funcname(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchecksum\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    779\u001b[0m         )\n\u001b[1;32m    780\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/io/parquet.py:784\u001b[0m, in \u001b[0;36mReadParquet.checksum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchecksum\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_info\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchecksum\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_expr/io/parquet.py:1356\u001b[0m, in \u001b[0;36mReadParquetFSSpec._dataset_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1338\u001b[0m     paths,\n\u001b[1;32m   1339\u001b[0m     fs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1354\u001b[0m     },\n\u001b[1;32m   1355\u001b[0m )\n\u001b[0;32m-> 1356\u001b[0m dataset_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_dataset_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1357\u001b[0m checksum \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/dataframe/io/parquet/arrow.py:1061\u001b[0m, in \u001b[0;36mArrowDatasetEngine._collect_dataset_info\u001b[0;34m(cls, paths, fs, categories, index, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1061\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mpa_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_wrapped_fs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_processed_dataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# Get file_frag sample and extract physical_schema\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pyarrow/dataset.py:797\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(elem, Dataset) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pyarrow/dataset.py:474\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 474\u001b[0m         fs, paths_or_selector \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_multiple_sources\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/pyarrow/dataset.py:382\u001b[0m, in \u001b[0;36m_ensure_multiple_sources\u001b[0;34m(paths, filesystem)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mNotFound:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(info\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mDirectory:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/neelesh/4_new_c4/fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_cudf/backends.py:716\u001b[0m, in \u001b[0;36mCudfDXBackendEntrypoint.read_parquet\u001b[0;34m(path, filesystem, engine, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     _raise_unsupported_parquet_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCudfEngine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;66;03m# EXPERIMENTAL filesystem=\"arrow\" support.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;66;03m# This code path uses PyArrow for IO, which is only\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# beneficial for remote storage (e.g. S3)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_cudf/backends.py:501\u001b[0m, in \u001b[0;36m_default_backend\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe.backend\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: /home/neelesh/4_new_c4/fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      2\u001b[0m components_stage \u001b[38;5;241m=\u001b[39m ConnectedComponents(\n\u001b[1;32m      3\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m      4\u001b[0m     jaccard_pairs_path\u001b[38;5;241m=\u001b[39mjaccard_pairs_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     jaccard_threshold\u001b[38;5;241m=\u001b[39mjaccard_threshold,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcomponents_stage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcc_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected Component took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/nemo_curator/modules/fuzzy_dedup.py:1428\u001b[0m, in \u001b[0;36mConnectedComponents.cc_workflow\u001b[0;34m(self, output_path)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcc_workflow\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_path):\n\u001b[0;32m-> 1428\u001b[0m     deduped_parsed_id_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_dedup_parsed_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     encoded_jaccard_pair_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_encoded_jaccard_pair(\n\u001b[1;32m   1430\u001b[0m         deduped_parsed_id_path\n\u001b[1;32m   1431\u001b[0m     )\n\u001b[1;32m   1432\u001b[0m     deduped_encoded_jaccard_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_dedup_encoded_jaccard_pair(\n\u001b[1;32m   1433\u001b[0m         encoded_jaccard_pair_path\n\u001b[1;32m   1434\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/nemo_curator/modules/fuzzy_dedup.py:1576\u001b[0m, in \u001b[0;36mConnectedComponents._write_dedup_parsed_id\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1572\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m performance_report_if_with_ts_suffix(\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofile_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnected-components-dedup-parsed-id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1575\u001b[0m ):\n\u001b[0;32m-> 1576\u001b[0m     ddf \u001b[38;5;241m=\u001b[39m \u001b[43mdask_cudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjaccard_pairs_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m512MB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1582\u001b[0m     id_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_column]\n\u001b[1;32m   1583\u001b[0m     unique_docs \u001b[38;5;241m=\u001b[39m ddf\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[1;32m   1584\u001b[0m         ConnectedComponents\u001b[38;5;241m.\u001b[39m_get_unique_ids_per_partition, id_columns\u001b[38;5;241m=\u001b[39mid_columns\n\u001b[1;32m   1585\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask_cudf/__init__.py:38\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config\u001b[38;5;241m.\u001b[39mset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe.backend\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcudf\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nemo/lib/python3.10/site-packages/dask/backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_parquet method registered to the cudf backend.\nOriginal Message: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: /home/neelesh/4_new_c4/fuzzy-dedup-output-2023-06-and-14/jaccard_similarity_results.parquet"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "components_stage = ConnectedComponents(\n",
    "    cache_dir=cache_dir,\n",
    "    jaccard_pairs_path=jaccard_pairs_path,\n",
    "    id_column=id_field,\n",
    "    # convert_str_ids=True,\n",
    "    jaccard_threshold=jaccard_threshold,\n",
    ")\n",
    "components_stage.cc_workflow(output_path=output_path)\n",
    "print(f\"Connected Component took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d579d9-0344-45a6-a565-78b1fbeddf9c",
   "metadata": {},
   "source": [
    "### 5.3.7 Duplicates Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8c531-10ec-448d-8413-f059b796226d",
   "metadata": {},
   "source": [
    "From the outputs of the Connect Component step, we can see that inter-snapshot dedup found 81,764,804 duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bd2d15-5c09-4fb1-a289-ce228f90713e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs_to_remove 81764804\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(base_dir, \"fuzzy-dedup-output-2023-06-and-14/connected_components.parquet\")\n",
    "cc_result = dask_cudf.read_parquet(output_path, split_row_groups=False).repartition(npartitions=1)\n",
    "\n",
    "# Set 'group' as the index and shuffle to ensure all same 'group' values are in the same partition\n",
    "cc_result = cc_result.set_index('group', shuffle='tasks')\n",
    "\n",
    "# Define a function to assign cumulative counts and filter duplicates\n",
    "def assign_cumcount(df):\n",
    "    df['cumcount'] = df.groupby(level=0).cumcount()\n",
    "    df = df[df['cumcount'] >= 1]\n",
    "    df = df.drop(columns=['cumcount'])\n",
    "    return df\n",
    "\n",
    "# Find duplicates by applying the function to each partition\n",
    "docs_to_remove = cc_result.map_partitions(assign_cumcount, meta=cc_result)\n",
    "\n",
    "# Reset the index\n",
    "docs_to_remove = docs_to_remove.reset_index()\n",
    "\n",
    "docs_to_remove = docs_to_remove[[\"dataset_id\", \"doc_id\"]]\n",
    "docs_to_remove = docs_to_remove.rename(columns={\"dataset_id\":\"to_remove_dataset_id\", \"doc_id\":\"to_remove_doc_id\"})\n",
    "docs_to_remove = docs_to_remove.reset_index(drop=True).persist()\n",
    "_ = wait(docs_to_remove)\n",
    "del _ \n",
    "\n",
    "print(\"docs_to_remove\", len(docs_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc75c4d-0eec-496f-b02f-a639b193522f",
   "metadata": {},
   "source": [
    "Before proceeding to duplicates removal, we suggest resharding the data to fix potentially empty partitions due to duplicates removal for single snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c6d7d6-9db5-4504-9d03-67c7ed69c409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sharding took:904.7163739204407\n"
     ]
    }
   ],
   "source": [
    "output_resharded_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"rpv2-2023-06-and-14-deduped-resharded\"))\n",
    "\n",
    "t0 = time.time()\n",
    "reshard_jsonl(\n",
    "    os.path.join(base_dir, \"rpv2-2023-06-and-14-deduped\"),\n",
    "    output_resharded_dir,\n",
    "    output_file_size=\"100M\",\n",
    "    start_index=0,\n",
    "    file_prefix=\"rpv2-2023-06-and-14-deduped\",\n",
    ")\n",
    "print(f\"Data sharding took:{time.time()-t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63546dd3-1560-4b38-91ce-84c004636657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 72780 files\n"
     ]
    }
   ],
   "source": [
    "from helper import convert_str_id_to_int\n",
    "\n",
    "input_dataset = DocumentDataset.read_json(os.path.join(base_dir, \"rpv2-2023-06-and-14-deduped-resharded\"), backend=\"cudf\")\n",
    "input_df = input_dataset.df[['raw_content','id']]\n",
    "meta = input_df._meta\n",
    "meta['doc_id']=np.int64([0])\n",
    "meta['dataset_id']=np.uint32([0])\n",
    "input_df = input_df.map_partitions(\n",
    "    convert_str_id_to_int,\n",
    "    id_column=\"id\",\n",
    "    meta=meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dfe6a9-a463-4d43-9f79-0d3df960961c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates and writing deduped dataset took 2084.46063041687 seconds\n"
     ]
    }
   ],
   "source": [
    "dedup_output_dir = expand_outdir_and_mkdir(os.path.join(base_dir, \"/rpv2-2023-06-and-14-inter-deduped\"))\n",
    "deduped_df = input_df.merge(docs_to_remove,\n",
    "                             left_on=['doc_id','dataset_id'],\n",
    "                             right_on=[\"to_remove_doc_id\", \"to_remove_dataset_id\"],\n",
    "                             how='left')\n",
    "\n",
    "deduped_df = deduped_df[deduped_df['to_remove_doc_id'].isna()].drop(columns=['to_remove_doc_id', \"to_remove_dataset_id\"]).reset_index(drop=True)\n",
    "\n",
    "t0 = time.time()\n",
    "deduped_df.to_parquet(dedup_output_dir)\n",
    "print(f\"Removing duplicates and writing deduped dataset took {time.time()-t0} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fea1e-45e5-423c-9187-17867c0ad2a7",
   "metadata": {},
   "source": [
    "We can verify that the deduped dataset has 1,585,546,179 documents, compared to 1,667,310,983 documents befoe dedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d174ea0f-440f-4311-a9c0-d3cc26683a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585546179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deduped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014e1a79-4967-4392-8cb8-6d822a3f57ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667310983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9977f5-fa49-4e63-9057-50fadba58a86",
   "metadata": {},
   "source": [
    "# 6. Quality Filtering\n",
    "<a id=\"filter\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b91e6-3156-4a1b-816b-500a54def99d",
   "metadata": {},
   "source": [
    "Web crawled dataset often has low quality documents that we do not want the model to learn from. We can perform quality filtering to remove low quality data. NeMo Curator offers modules for both classifier-based and heuristic-based filtering. In this tutorial, we will perform heuristic filtering using a list of heuristic filters to improve data quality.\n",
    "\n",
    "Curator provides a generic list of heuristic filters but for this tutorial, we only select 10 filters for demo purposes. The selected filters are given in `config/heuristic_filter_en.yaml`.\n",
    "\n",
    "Heuristic filtering in Curator is a cpu module so we will need to use the cpu cluter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1347d09-8bc5-453b-aa4a-4b75c4b3b47a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Workers = 256\n"
     ]
    }
   ],
   "source": [
    "scheduler_address = os.getenv('SCHEDULER_ADDRESS')\n",
    "cpu_client = get_client(scheduler_address=scheduler_address)\n",
    "print(f\"Num Workers = {get_num_workers(cpu_client)}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49273a8b-848f-4f24-a0ba-3c0b478d17cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nemo_curator\n",
    "from nemo_curator.utils.config_utils import build_filter_pipeline\n",
    "\n",
    "filter_config_file = os.path.join(base_dir, \"config/heuristic_filter_en.yaml\")\n",
    "hf_input_data_dir = os.path.join(base_dir, \"rpv2-2023-06-and-14-inter-deduped\")\n",
    "kept_document_dir =  expand_outdir_and_mkdir(os.path.join(base_dir,'rpv2-2023-06-and-14-heuristic-filtering','hf.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5284b6f-c87e-4027-a802-ab08b92610cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 72780 files\n",
      "Writing to disk complete for 72780 partitions\n",
      "Time taken for Heuristic filtering: 5647.508106470108 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Load dataset\n",
    "dataset = DocumentDataset.read_parquet(hf_input_data_dir)\n",
    "\n",
    "# construct pipeline from config\n",
    "filter_pipeline = build_filter_pipeline(filter_config_file)\n",
    "\n",
    "# filter data and write to disk\n",
    "filtered_dataset = filter_pipeline(dataset)\n",
    "filtered_dataset.to_parquet(kept_document_dir)\n",
    "\n",
    "print(f\"Time taken for Heuristic filtering: {time.time()-t0} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0658a-97f9-412c-8eef-68f6ab0b4be6",
   "metadata": {},
   "source": [
    "After filitering, we have 1,229,679,047 documents left, removing 355,867,132 documents from the deduped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da60070-f78c-43fe-8bc0-fcbd839b7021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229679047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92ae5e-7397-4ad9-9dec-cb93eefc3dde",
   "metadata": {},
   "source": [
    "[Optional] Examine example low quality documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e4b615-1eaa-4050-b191-28a48166a560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_dataframe_complement\n",
    "\n",
    "original_df = dd.read_parquet(hf_input_data_dir)\n",
    "filtered_df = dd.read_parquet(kept_document_dir)\n",
    "removed_df = get_dataframe_complement(original_df, filtered_df)\n",
    "removed_df_example = removed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468233aa-d2a9-4e80-a815-e1a645213c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(removed_df_example.raw_content.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee129f8-1fc5-401c-aa73-42fb254539c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(removed_df_example.raw_content.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60a9b9-9158-43d6-9ea4-1f544c6f816e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
